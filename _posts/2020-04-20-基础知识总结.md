---
title: 基础知识总结
description: Java
categories:
 - interview
tags:
---

<!-- more -->



### 一、Spring
#### 1.1 spring bean的生命周期
	Spring Bean的生命周期只有这四个阶段。把这四个阶段和每个阶段对应的扩展点糅合在一起虽然没有问题，但是这样非常凌乱，难以记忆。要彻底搞清楚Spring的生命周期，首先要把这四个阶段牢牢记住。实例化和属性赋值对应构造方法和setter方法的注入，初始化和销毁是用户能自定义扩展的两个阶段。在这四步之间穿插的各种扩展点，稍后会讲。（https://www.jianshu.com/p/1dec08d290c1）
	1.	实例化 Instantiation  实例化前后调用InstantiationAwareBeanPostProcessor
	2.	属性赋值 Populate
	3.	初始化 Initialization 初始化前后调用BeanPostProcessor
	4.	销毁 Destruction
	实例化 -> 属性赋值 -> 初始化 -> 销毁
	1.	Aware类型的接口 Aware都是在初始化阶段之前调用的
	1.	BeanNameAware
	2.	BeanClassLoaderAware
	3.	BeanFactoryAware
	Aware Group2
	1.	EnvironmentAware
	2.	EmbeddedValueResolverAware 这个知道的人可能不多，实现该接口能够获取Spring EL解析器，用户的自定义注解需要支持spel表达式的时候可以使用，非常方便。
	3.	ApplicationContextAware(ResourceLoaderAware\ApplicationEventPublisherAware\MessageSourceAware) 这几个接口可能让人有点懵，实际上这几个接口可以一起记，其返回值实质上都是当前的ApplicationContext对象，因为ApplicationContext是一个复合接口
	至于剩下的两个生命周期接口就很简单了，实例化和属性赋值都是Spring帮助我们做的，能够自己实现的有初始化和销毁两个生命周期阶段。
	1.	InitializingBean
	2.	DisposableBean 类似于InitializingBean，对应生命周期的销毁阶段。
	总结
	SpringBean的生命周期分为四个阶段和多个扩展点
	•	实例化 Instantiation
	•	属性赋值 Populate
	•	初始化 Initialization
	•	销毁 Destruction
	多个扩展点
	◦	BeanPostProcessor
	◦	InstantiationAwareBeanPostProcessor
	◦	Aware
	▪	BeanNameAware
	▪	BeanClassLoaderAware
	▪	BeanFactoryAware
	▪	EnvironmentAware
	▪	EmbeddedValueResolverAware	    ▪ApplicationContextAware(ResourceLoaderAware\ApplicationEventPublisherAware\MessageSourceAware)
	◦	生命周期
	▪	InitializingBean
	▪	DisposableBean
	至此，Spring Bean的生命周期介绍完毕

####Spring动态代理类的生成
	beanFactoryPostProcessoer 动态代理 FactoryBean
	BeanFactoryPostProcessor ---> 普通Bean构造方法 ---> 设置依赖或属性 ---> @PostConstruct ---> InitializingBean ---> initMethod
	https://www.cnblogs.com/piepie/p/9061076.html
	大致流程：实现BeanFactoryPostProcessor接口，在postProcessBeanFactory方法里面往beanFactory塞自己的beanDefinition即可。

#####1.	为什么需要代理模式？
		代理模式可以避免直接引用目标对象或者修改目标对象，支持对目标对象做包装、扩展
#####2.	讲讲静态代理模式的优点及其瓶颈？
		1.可以做到在不修改目标对象的功能前提下,对目标功能扩展.
	　　2.缺点:因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护
#####4.	如何使用 Java 反射实现动态代理？
	底层就是method.invoke反射调用
    public class ProxyFactory{

    //维护一个目标对象
    private Object target;
    public ProxyFactory(Object target){
        this.target=target;
    }
	 //给目标对象生成代理对象
    public Object getProxyInstance(){
        return Proxy.newProxyInstance(
                target.getClass().getClassLoader(),
                target.getClass().getInterfaces(),
                new InvocationHandler() {
                    @Override
                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                        System.out.println("开始事务2");
                        //运用反射执行目标对象方法
                        Object returnValue = method.invoke(target, args);
                        System.out.println("提交事务2");
                        return returnValue;
                    }
                }
        );
    }

}
#####6.	谈谈对Cglib 类增强动态代理的实现？

    public class ProxyFactory implements MethodInterceptor{
    //维护目标对象
    private Object target;

    public ProxyFactory(Object target) {
        this.target = target;
    }

    //给目标对象创建一个代理对象
    public Object getProxyInstance(){
        //1.工具类
        Enhancer en = new Enhancer();
        //2.设置父类
        en.setSuperclass(target.getClass());
        //3.设置回调函数
        en.setCallback(this);
        //4.创建子类(代理对象)
        return en.create();

    }

    @Override
    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
        System.out.println("开始事务...");

        //执行目标对象的方法
        Object returnValue = method.invoke(target, args);

        System.out.println("提交事务...");

        return returnValue;
    }
}

#####7.	怎么理解面向切面编程的切面？
	切面（Aspect）：其实就是共有功能的实现。如日志切面、权限切面、事务切面等。在实际应用中通常是一个存放共有功能实现的普通Java类。
#####9.	讲解JDK 动态代理和 CGLIB 代理原理以及区别？
	如果加入容器的目标对象有实现接口,用JDK代理
	如果目标对象没有实现接口,用Cglib代理 　　
	如果目标对象实现了接口，且强制使用cglib代理，则会使用cglib代理。
#####11.	讲解Spring 框架中如何基于 AOP 实现的事务管理？
	附：spring事务失效的原因？
	一、异常
	二、事务是基于动态代理实现，方法必须通过动态代理对象获取才会生效，否则失效。比如 Service的A()调用B()，调用方式为this.B() (或者直接B()) 因为拿到的是实现类而非代理类的B() 所以实际效果相当于把B方法内容嵌入A，而没有走动态代理，需要传入Service.B().  具体bean的方法， Spring的bean都是代理对象，而class里面的this 只是实例本身，而非代理。总的来说，一句话，必须通过spring bean（代理对象）访问的方法才具备事务生效
	在Spring框架中最常用的就是声明式配置事务，而声明式配置可以基于xml进行配置，也可以基于注解进行配置。
	@Transactional注解，其中@Transactional值有以下属性：
	以上属性主要针对isolation和propagation来讲，这两个属性的值都是枚举。
	Isolation(事务隔离级别)该属性的作用是表事务隔离开，对于一些多并发的访问或者更新同一个数据库时，必须要设置该属性，要不然会出现脏读，更新丢失等问题。而isolation属性就很有效的解决该问题，其中isolation属性提供了不同隔离级别的枚举值：
	隔离级别 作用
	Isolation.READ_UNCOMMITTED 读取未提交数据(会出现脏读, 不可重复读)
	Isolation.READ_COMMITTED 读取已提交数据(会出现不可重复读和幻读)
	Isolation.REPEATABLE_READ 可重复读(会出现幻读)
	Isolation.SERIALIZABLE 串行化
	Propagation(事务传播行为)该属性的作用是该如何创建事务，怎样加入事务：
	传播行为 作用
	Propagation.REQUIRED 如果有事务,那么加入事务,没有的话新建一个(不写的情况下)
	Propagation.NOT_SUPPORTED 容器不为这个方法开启事务
	Propagation.REQUIRES_NEW 不管是否存在事务,都创建一个新的事务,原来的挂起,新的执行完毕,继续执行老的事务
	Propagation.MANDATORY 必须在一个已有的事务中执行,否则抛出异常
	Propagation.NEVER 必须在一个没有的事务中执行,否则抛出异常(与Propagation.MANDATORY相反)
	Propagation.SUPPORTS 如果其他bean调用这个方法,在其他bean中声明事务,那就用事务.如果其他bean没有声明事务,那就不用事务
#####12.	谈谈对控制反转的设计思想的理解？
	因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。
#####14.	Spring IOC 怎么管理 Bean 之间的依赖关系，怎么避免循环依赖？
	https://my.oschina.net/zhangxufeng/blog/3096394 
		步骤一：beanA进行初始化，并且将自己进行初始化的状态记录下来，并提前向外暴露一个单例工程方法，从而使其他bean能引用到该bean（可能读完这一句，您仍然心存疑惑，没关系，继续往下读）
		步骤二：beanA中有beanB的依赖，于是开始初始化beanB。
	　　步骤三：初始化beanB的过程中又发现beanB依赖了beanA,于是又进行beanA的初始化，这时发现beanA已经在进行初始化了，程序发现了存在的循环依赖，然后通过步骤一中暴露的单例工程方法拿到beanA的引用（注意，此时的beanA只是完成了构造函数的注入但为完成其他步骤），从而beanB拿到beanA的引用，完成注入，完成了初始化，如此beanB的引用也就可以被beanA拿到，从而beanA也就完成了初始化。
	　　spring进行bean的加载的时候，首先进行bean的初始化（调用构造函数），然后进行属性填充。在这两步中间，spring对bean进行了一次状态的记录，也就是说spring会把指向只完成了构造函数初始化的bean的引用通过一个变量记录下来，明白这一点对之后的源码理解至关重要。
	https://www.cnblogs.com/myseries/p/11801097.html
	主要是理解bean的初始化过程中的三级缓存机制
	https://cloud.tencent.com/developer/article/1497692
	// 从上至下 分表代表这“三级缓存”
	private final Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256); //一级缓存
	private final Map<String, Object> earlySingletonObjects = new HashMap<>(16); // 二级缓存
	private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<>(16); // 三级缓存
	注：AbstractBeanFactory继承自DefaultSingletonBeanRegistry~
	singletonObjects：用于存放完全初始化好的 bean，从该缓存中取出的 bean 可以直接使用
	earlySingletonObjects：提前曝光的单例对象的cache，存放原始的 bean 对象（尚未填充属性），用于解决循环依赖
	singletonFactories：单例对象工厂的cache，存放 bean 工厂对象，用于解决循环依赖
#####15.	对Spring IOC 容器的依赖注入的理解？
	Spring所倡导的开发方式就是如此，所有的类都会在spring容器中登记，告诉spring你是个什么东西，你需要什么东西，然后spring会在系统运行到适当的时候，把你要的东西主动给你，同时也把你交给其他需要你的东西。所有的类的创建、销毁都由 spring来控制，也就是说控制对象生存周期的不再是引用它的对象，而是spring。对于某个具体的对象而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转
	DI—Dependency Injection，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。
	IoC和DI由什么关系呢？其实它们是同一个概念的不同角度描述，由于控制反转概念比较含糊（可能只是理解为容器控制对象这一个层面，很难让人想到谁来维护对象关系），所以2004年大师级人物Martin Fowler又给出了一个新的名字：“依赖注入”，相对IoC 而言，“依赖注入”明确描述了“被注入对象依赖IoC容器配置依赖对象”
	总结，IOC  DI 是同一概念的不同角度的解释，IOC，站在对象的角度，控制依赖对象的产生权被反转，交给了IOC容器，DI是站在容器的角度，对象之间的依赖关系有容器统一注入，增强扩展性
#####17.	BeanFactory 和 FactoryBean 有什么区别？
	BeanFactory，以Factory结尾，表示它是一个工厂类(接口)，用于管理Bean的一个工厂。在Spring中，BeanFactory是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。
	　　以Bean结尾，表示它是一个Bean，不同于普通Bean的是：它是实现了FactoryBean<T>接口的Bean，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&符号来获取。
#####18.	BeanFactory 和 ApplicationContext 又有什么不同？
	BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationContext是BeanFactory的子接口。
	BeanFactory和ApplicationContext是Spring的两大核心接口，都可以当做Spring的容器。其中ApplicationContext是BeanFactory的子接口。
	BeanFactory 可以理解为含有 bean 集合的工厂类。BeanFactory 包含了种 bean 的定义，以便在接收到客户端请求时将对应的 bean 实例化。
	BeanFactory 还能在实例化对象的时生成协作类之间的关系。此举将 bean 自身与 bean 客户端的配置中解放出来。BeanFactory 还包含了 bean 生命周期的控制，调用客户端的初始化方法（initialization methods）和销毁方法（destruction methods）。
	从表面上看，ApplicationContext 如同 BeanFactory 一样具有 bean 定义、bean 关联关系的设置，根据请求分发 bean 的功能。但 ApplicationContext 在此基础上还提供了其他的功能：
	提供了支持国际化的文本消息
	统一的资源文件读取方式
	已在监听器中注册的 bean 的事件
	public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory,
        MessageSource, ApplicationEventPublisher, ResourcePatternResolver {}
### 二、多线程
#### 2.1 基本概念
#####1.	多线程并发和并行？
	线程并发，CPU切换，微观上交替执行，宏观上是同时执行；线程并行，真正意义上的并行，多CPU同时执行，无论微观还是宏观都是同时执行。
	⾕歌著名⼯程师罗布·派克（Rob Pike）说过，“并发就是同时应对 （Dealing With）多件事情的能⼒，并⾏是同时执⾏（Doing）多件事情的 能⼒”。这句话⾮常透彻地阐述了并发和并⾏的区别，在于“应对”和“执 ⾏”。
	解释一：并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔发生。
	解释二：并行是在不同实体上的多个事件，并发是在同一实体上的多个事件
#####2. IO密集型 和CPU密集型任务
	根据任务所需要的cpu和io资源的量可以分为CPU密集型任务:  主要是执行计算任务，响应时间很快，cpu一直在运行，这种任务cpu的利用率很高
	IO密集型任务：主要是进行IO操作，执行IO操作的时间较长，这是cpu出于空闲状态，导致cpu的利用率不高
	为了合理最大限度的使用系统资源同时也要保证的程序的高性能，可以给CPU密集型任务和IO密集型任务配置一些线程数。
	CPU密集型：线程个数为CPU核数。这几个线程可以并行执行，不存在线程切换到开销，提高了cpu的利用率的同时也减少了切换线程导致的性能损耗
	IO密集型：线程个数为CPU核数的两倍。到其中的线程在IO操作的时候，其他线程可以继续用cpu，提高了cpu的利用率 
	线程是否越多越好？ 分析如下：
	一个计算为主的程序（专业一点称为CPU密集型程序）。多线程跑的时候，可以充分利用起所有的cpu核心，比如说4个核心的cpu,开4个线程的时候，可以同时跑4个线程的运算任务，此时是最大效率。
	但是如果线程远远超出cpu核心数量 反而会使得任务效率下降，因为频繁的切换线程也是要消耗时间的。
	因此对于cpu密集型的任务来说，线程数等于cpu数是最好的了。
	如果是一个磁盘或网络为主的程序（IO密集型）。一个线程处在IO等待的时候，另一个线程还可以在CPU里面跑，有时候CPU闲着没事干，所有的线程都在等着IO，这时候他们就是同时的了，而单线程的话此时还是在一个一个等待的。我们都知道IO的速度比起CPU来是慢到令人发指的。所以开多线程，比方说多线程网络传输，多线程往不同的目录写文件，等等。
	此时 线程数等于IO任务数是最佳的。
#####3.线程安全问题
	多个线程对共享资源的操作可能产生的数据污染问题。全局变量、或者局部变量发生逃逸。
	附：逃逸分析（https://www.xttblog.com/?p=3158）
	逃逸分析是一种JVM优化手段，JVM尽量避免太多对象在堆上进行分配，提高垃圾回收效率，未开启逃逸分析，所有对象都必须在堆上进行分配，局部变量只是引用指针。开启逃逸分析之后，-XX:+DoEscapeAnalysis 一些未发生逃逸的局部变量，可以直接在栈上进行分配，方法执行完后，直接回收。
#####4.共享变量的内存可见性问题
	1）多核CPU  多级缓存的MESI协议   CPU级别 L1 L2缓存不被污染  L3共享
	2）内存屏障   多线程级别 并发
	3）指令重排      DCL 失效问题  必须加volatile
	https://blog.csdn.net/mnb65482/article/details/80458571
	变量可见性是指变量在多个线程工作内存和主内存保持一致，一个线程修改了变量，其他线程能够看到发送的状态变化，涉及到指令重排。实现原理是JVM的内存屏障。volatile通过内存屏障和禁止指令重排实现可见性。
	附：指令重排和内存屏障。
	指令重排：代码指令并不是严格按照代码语句的顺序执行，而是采取乱序执行，直接运行当前有能力执行的后续指令，避开获取下一条指令数据所需数据造成的等待，CPU可以大大提高执行效率。As-if-serial语义的意思是，所有的动作(Action)都可以为了优化而被重排序，但是必须保证它们重排序后的结果和程序代码本身的应有结果是一致的。Java编译器、运行时和处理器都会保证单线程下的as-if-serial语义。为了保证这一语义，重排序不会发生在有数据依赖的操作之中.
	内存屏障（Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。
      内存屏障可以被分为以下几种类型（读屏障、写屏障）
	LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
	StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
	LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
	StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。        在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。
#####5.Java中原子性
	原子性：不被多线程调度机制打断的操作，一旦开始一直到结束，不会切换到其他线程，切换上下文。Java中的CAS操作,AtomicLong实现原理？
	CAS是 compareAndSwap java解决线程同步的乐观锁机制，修改变量的时候检查当前值，符合的话修改成功，否则不做任何操作。
	CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。无论哪种情况，它都会在 CAS 指令之前返回该 位置的值。（在 CAS 的一些特殊情况下将仅返回 CAS 是否成功，而不提取当前 值。）CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。
	
#####7.什么是伪共享,为何会出现，以及如何避免？
	false sharing ：不同的线程操作同一个缓存行，导致的竞争冲突。
	详见：https://www.jianshu.com/p/a4358d39adac
 	ConccuentHashMap size底层使用了填充解决伪共享
	CPU缓存是以缓存行为单位进行操作的。产生伪共享问题的根源在于不同的核同时操作同一个缓存行。
	可以通过填充来解决伪共享问题，Java8 中引入了@sun.misc.Contended注解来自动填充。
	并不是所有的场景都需要解决伪共享问题，因为CPU缓存是有限的，填充会牺牲掉一部分缓存。

#####8.可重入锁、乐观锁、悲观锁、公平锁、非公平锁、独占锁、共享锁？
	独占锁：I
	共享锁：S
	ReentrantLock基于aqs实现，他的基本原理是aqs的status为0时表示锁被占用，为1时表示锁被释放。ReentrantLock在使用时需要显式的获取和释放锁，一般用try finally来实现，相对于synchronized，reentrantlock提供了功能更强大的api，例如超时锁、可中断锁、公平锁、非公平锁、非阻塞锁获取等等，ReentrantLock是独占锁，它分为公平锁和非公平锁两种模式，公平锁保证按照获取锁的顺序来得到锁，非公平锁则则可以进行抢占，而像countdownlatch、semaphore等组件是基于共享锁实现的，也就是同一时刻可以有多个线程获取锁，锁的数量由用户指定
	独占公平锁原理：
	调用aqs的lock方法尝试获取锁
	调用上层组件reentrantlock的trylock方法尝试获取同步状态，如果获取成功，则成功获取锁，如果获取失败，则被构造成node节点后，利用cas线程安全的加到同步对列的末尾然后该线程进入自旋状态
	自旋时首先判断前驱节点是否为头节点并且能否成功获取到同步状态，如果都成立，则成功获取锁，如果不成立，则先讲将其前驱节点等待状态设置为signal，然后利用Locksupport挂起，等待前驱线程唤醒当被前驱节点唤醒，且成功回去同步状态后，才成功获取到了锁。对于释放锁，就是通过aqs设置同步状态为1的过程，同时唤醒后继节点
	独占非公平锁：
	独占非公平锁与公平锁的唯一区别是，在获取锁时，不管是否有线程在等待锁，直接通过aqs修改同步状态，进行锁抢占，如果抢占失败，那后面的流程就与公平锁一致了。
	共享锁原理：
	共享锁的基本流程与独占锁相同，主要区别在于判断锁获取的条件上，由于是共享锁，也就允许多个线程同时获取，所以同步状态的数量同时的大于1的，如果同步状态为非0，则线程就可以获取锁，只有当同步状态为0时，才说明共享数量的锁已经被全部获取，其余线程只能等待。共享锁的释放过程正好与之相反，释放锁对应的AQS操作时增加同步状态的值。
	补充：锁的四种状态：偏向锁、轻量级锁、重量级锁、无锁
	偏向锁：对象头markWord记录占用锁的线程Id，下次占用会比较线程id，如果是，直接锁定，如果不是，进入轻量级锁，竞争资源。其实是消除线程同步，当做是给一个线程使用的资源。标准解释：线程在大多数情况下并不存在竞争条件，使用同步会消耗性能，而偏向锁是对锁的优化，可以消除同步，提升性能。当一个线程获得锁，会将对象头的锁标志位设为01,进入偏向模式.偏向锁可以在让一个线程一直持有锁，在其他线程需要竞争锁的时候，再释放锁。	
	轻量级锁：大部分资源都是快速释放，避免进入到系统内核级别的线程切换，采用CAS自旋，不挂起，不让出CPU，消耗CPU，等待一会即可。标准解释：当线程A获得偏向锁后，线程B进入竞争状态，需要获得线程A持有的锁，那么线程A撤销偏向锁，进入无锁状态。线程A和线程B交替进入临界区，偏向锁无法满足，膨胀到轻量级锁，锁标志位设为00。	
	重量级锁：竞争激烈，多个线程同时竞争资源，进入线程阻塞。标准解释：当多线程交替进入临界区，轻量级锁hold得住。但如果多个线程同时进入临界区，hold不住了，膨胀到重量级锁	
	见https://www.jianshu.com/p/0f44e797cdd9

#####9. ThreadLocal 的实现原理
	线程独享副本 .  利用线程Thread内部维护的ThreadLocalMap存储每个线程维护的ThreadLocal对象map  key为ThreadLocal对象，value为值。
	ThreadLocal 作为变量的线程隔离方式，其内部是如何做的？
	详见https://www.jianshu.com/p/69ae8c213b30  讲的可以	
	特别注意的是，ThreadLocalMap的Entry是弱引用，存在垃圾回收误区，不会被GC，只有get,set,remove,remove,rehash时候会把判断置空，所以必须显示的remove ThreadLocal对象。
	https://www.toutiao.com/a6560547865880429070/
	摘自详细解释：上文也提到了，Entry继承自WeakReference，大家都知道WeakReference（弱引用）的特性，只要从根集出发的引用中没有有效引用指向该对象，则该对象就可以被回收，这里的有效引用并不包含WeakReference，所以弱引用不影响对象被GC。
	这里被WeakReference引用的对象是哪个呢？可以看Entry的构造方法，很容易看出指的是ThreadLocal自身，也就是说ThreadLocal自身的回收不受ThreadLocalMap的这个弱引用的影响，让用户减轻GC的烦恼。
	但是不用做些什么吗？这么简单？其实不然，ThreadLocalMap还做了其他的工作，试想一下，ThreadLocal对象如果外界没有有效引用，是能够被GC，但是Entry呢？Entry也能自动被GC吗，当然不行，Entry还被ThreadLocalMap的table数组强引用着呢。
	所以ThreadLocalMap该做点什么？我看看ThreadLocalMap的expungeStaleEntry这个方法，这个方法在ThreadLocalMap get、set、remove、rehash等方法都会调用到，看下面标红的两处代码，第一处是将remove的entry赋空，第二次处是找到已经被GC的ThreadLocal，然后会清理掉table数组对entry的引用。这样entry在后续的GC中就会被回收。
	关于强引用、弱引用、软引用
	详见https://www.jianshu.com/p/86efa167a627
	1，强引用。特点：我们平常典型编码Object obj = new Object()中的obj就是强引用。通过关键字new创建的对象所关联的引用就是强引用。 当JVM内存空间不足，JVM宁愿抛出OutOfMemoryError运行时错误（OOM），使程序异常终止，也不会靠随意回收具有强引用的“存活”对象来解决内存不足的问题。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，具体回收时机还是要看垃圾收集策略。
    2，软引用。特点：软引用通过SoftReference类实现。 软引用的生命周期比强引用短一些。只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象：即JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。
	   应用场景：软引用通常用来实现内存敏感的缓存。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。
	常见场景：图片缓存。
	3，弱引用。弱引用通过WeakReference类实现。 弱引用的生命周期比软引用短。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。
	应用场景：弱应用同样可用于内存敏感的缓存。
	常见场景：handler的使用防止内存泄露。（上图这只是弱引用的例子，handler最好是在activity销毁的时候直接remove掉所有消息）
    4，虚引用。特点：虚引用也叫幻象引用，通过PhantomReference类来实现。无法通过虚引用访问对象的任何属性或函数。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。
	ReferenceQueue queue = new ReferenceQueue ();
	PhantomReference pr = new PhantomReference (object, queue); 
	程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。
	应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。

#####10. CyclicBarrier内部的实现与 CountDownLatch 区别
	CyclicBarrier底层基于AQS的RetrantLock， CountDownLatch直接基于AQS，共享锁。CyclicBarrier可以循环使用，CountDownLatch使用一次，计数器到0停止
	https://segmentfault.com/a/1190000014818613

#####11.随机数生成器 Random 类如何使用 CAS 算法保证多线程下新种子的唯一性？
	Random和ThreadLocalRandom
	AtomicLong + CAS .
	Random下，不同的线程会同时对seed更新，产生共享资源竞争，采用的CAS算法会导致自旋。为解决该问题，产生ThreadLocalRandom
	https://www.iteye.com/blog/pzh9527-2428066
	
#####12. ThreadLocalRandom 是如何利用 ThreadLocal 的原理来解决 Random 的局限性？
	https://www.iteye.com/blog/pzh9527-2428066
	1.7和1.8实现有不同
#####13.Spring 框架中如何使用 ThreadLocal 实现 request scope 作用域 Bean？
	https://blog.csdn.net/weixin_34344677/article/details/89722447
	简单来说，利用InheritableThreadLocal，继承父线程的变量属性

#####14.并发包中锁的实现底层（对AQS的理解）？
	https://www.jianshu.com/p/c0afad4e5064
	简单来说，AQS底层是一个volitile 的锁状态state和一个双向队列CLH组成，当一个线程获得资源，state置为1，并将占用线程（有效线程）置为自己，如果资源已经被锁，加入到CLS队列尾部，阻塞等待被唤醒（阻塞之前有一次的CAS，毕竟阻塞的成本较大）。底层使用的模板方法设计模式，本身属于抽象类。
#####15.讲讲独占锁 ReentrantLock 原理？
	核心原原理：基于AQS+CAS 
	公平与非公平区别	

    protected final boolean tryAcquire(int acquires) {             
     final Thread current = Thread.currentThread();             
     int c = getState();                                        
     if (c == 0) {                                              
         if (!hasQueuedPredecessors() &&                        
             compareAndSetState(0, acquires)) {                 
             setExclusiveOwnerThread(current);                  
             return true;                                       
         }                                                      
     }                                                          
     else if (current == getExclusiveOwnerThread()) {           
         int nextc = c + acquires;                              
         if (nextc < 0)                                         
             throw new Error("Maximum lock count exceeded");    
         setState(nextc);                                       
         return true;                                           
     }                                                          
     return false;                                               }   
     final boolean nonfairTryAcquire(int acquires) {                    
    final Thread current = Thread.currentThread();                 
    int c = getState();                                            
    if (c == 0) {                                                  
        if (compareAndSetState(0, acquires)) {                     
            setExclusiveOwnerThread(current);                      
            return true;                                           
        }                                                          
    }                                                              
    else if (current == getExclusiveOwnerThread()) {               
        int nextc = c + acquires;                                  
        if (nextc < 0) // overflow                                 
            throw new Error("Maximum lock count exceeded");        
        setState(nextc);                                           
        return true;                                               
    }                                                              
    return false;                                                  
}                                                                      
 

#####16. 谈谈读写锁 ReentrantReadWriteLock 原理？
	读操作的锁叫共享锁，写操作的锁叫排他锁。就是遇见写锁就需互斥。那么以此可得出读读共享，写写互斥，读写互斥，写读互斥。

#####17. StampedLock 锁原理的理解？
	StampedLock 的性能之所以比 ReadWriteLock 还要好，其关键是 StampedLock 支持乐观读的方式。ReadWriteLock 支持多个线程同时读，但是当多个线程同时读的时候，所有的写操作会被阻塞；而 StampedLock 提供的乐观读，是允许一个线程获取写锁的，也就是说不是所有的写操作都被阻塞。

#####19. ConcurrentLinkedQueue 内部是如何使用 CAS 非阻塞算法来保证多线程下入队出队操作的线程安全？
	单向链表队列，包含头尾节点head tail，大致原理：出队列，cas 头结点head；入队列，cas 为节点tail 
#####20. 基于链表的阻塞队列 LinkedBlockingQueue 原理。
	https://www.jianshu.com/p/cc2281b1a6bc
	ArrayBlockingQueue由于其底层基于数组，并且在创建时指定存储的大小，在完成后就会立即在内存分配固定大小容量的数组元素，因此其存储通常有限，故其是一个“有界“的阻塞队列；而LinkedBlockingQueue可以由用户指定最大存储容量，也可以无需指定，如果不指定则最大存储容量将是Integer.MAX_VALUE，即可以看作是一个“无界”的阻塞队列，由于其节点的创建都是动态创建，并且在节点出队列后可以被GC所回收，因此其具有灵活的伸缩性。但是由于ArrayBlockingQueue的有界性，因此其能够更好的对于性能进行预测，而LinkedBlockingQueue由于没有限制大小，当任务非常多的时候，不停地向队列中存储，就有可能导致内存溢出的情况发生。
	其次，ArrayBlockingQueue中在入队列和出队列操作过程中，使用的是同一个lock，所以即使在多核CPU的情况下，其读取和操作的都无法做到并行，而LinkedBlockingQueue的读取和插入操作所使用的锁是两个不同的lock，它们之间的操作互相不受干扰，因此两种操作可以并行完成，故LinkedBlockingQueue的吞吐量要高于ArrayBlockingQueue。
	https://baijiahao.baidu.com/s?id=1659586116326532964&wfr=spider&for=pc
	Java中的BlockingQueue主要有两种实现，分别是ArrayBlockingQueue 和 LinkedBlockingQueue。
	ArrayBlockingQueue是一个用数组实现的有界阻塞队列，必须设置容量。
	LinkedBlockingQueue是一个用链表实现的有界阻塞队列，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。
	这里的问题就出在：不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE。也就是说，如果我们不设置LinkedBlockingQueue的容量的话，其默认容量将会是Integer.MAX_VALUE。而newFixedThreadPool中创建LinkedBlockingQueue时，并未指定容量。此时，LinkedBlockingQueue就是一个无边界队列，对于一个无边界队列来说，是可以不断的向队列中加入任务的，这种情况下就有可能因为任务过多而导致内存溢出问题。
	看阿里巴巴开发手册并发编程这块有一条：线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式。
#####21. 阻塞队列LinkedBlockingQueue 内部是如何使用两个独占锁 ReentrantLock 以及对应的条件变量保证多线程先入队出队操作的线程安全？
	reetrantLock  takeLock  putLock   
    condition   notEmpty  notFull  
#####22. Semaphore 的内部实现是怎样的？
	Semaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于给线程规定一个量从而控制允许活动的线程数。
#####23. 并发组件CopyOnWriteArrayList 是如何通过写时拷贝实现并发安全的 List？
	在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此如果每次读取都进行加锁操作，其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内部数据，毕竟读操作是线程安全的。
	这和 ReentrantReadWriteLock 读写锁的思想非常类似，也就是 读读共享、写写互斥、读写互斥、写读互斥。JDK中提供了 CopyOnWriteArrayList 类，相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待，读操作的性能得到大幅度提升
	CopyOnWriteArrayList 类的所有可变操作（add，set等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，并不直接修改原有数组对象，而是对原有数据进行一次拷贝，将修改的内容写入副本中。写完之后，再将修改完的副本替换成原来的数据，这样就可以保证写操作不会影响读操作了。
	从 CopyOnWriteArrayList 的名字可以看出，CopyOnWriteArrayList 是满足 CopyOnWrite 的 ArrayList，所谓 CopyOnWrite 的意思：、就是对一块内存进行修改时，不直接在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后，再将原来指向的内存指针指到新的内存，原来的内存就可以被回收
	https://www.jianshu.com/p/9b6a4d0b94ac
#####24 其他
	1.生产消费者
	2.wait  notify  sleep  
	3.交替打印
	关于线程状态
	NEW  —》RUNABLE -》BLOCKED
                    -》WAITING      TIME_WAITING  
                    -》TERMINATE
	遇到同步方法时候进入blocked
	获取锁，失败，进入重量级锁，会进入waiting 或者time waiting （加入超时时间）
	对象头 重量级锁会记录 monitor对象指针，monitor对象：
	Monitor对象
	每个对象都有一个Monitor对象相关联，Monitor对象中记录了持有锁的线程信息、等待队列等。Monitor对象包含以下三个字段：
	•	_owner 记录当前持有锁的线程
	•	_EntryList 是一个队列，记录所有阻塞等待锁的线程
	•	_WaitSet 也是一个队列，记录调用 wait() 方法并还未被通知的线程
	当线程持有锁的时候，线程id等信息会拷贝进owner字段，其余线程会进入阻塞队列entrylist，当持有锁的线程执行wait方法，会立即释放锁进入waitset，当线程释放锁的时候，owner会被置空，公平锁条件下，entrylist中的线程会竞争锁，竞争成功的线程id会写入owner，其余线程继续在entrylist中等待。

#####25. 开启线程的三种方式？
	Thread Runable  方式3：直接在函数体使用（匿名内部类，其实也是属于第二种实现方式的特例。）
#####26. 线程和进程的区别？
	进程：是执行中一段程序，即一旦程序被载入到内存中并准备执行，它就是一个进程。进程是表示资源分配的的基本概念，又是调度运行的基本单位，是系统中的并发执行的单位。
	线程：单个进程中执行中每个任务就是一个线程。线程是进程中执行运算的最小单位。
#####29. 如何控制某个方法允许并发访问线程的个数？
		Semaphore
#####30. 在Java中wait和seelp方法的不同；
	sleep是Thread类的静态方法,是线程用来控制自身流程的,它会使此线程暂停执行指定的时间,而把执行机会让给其他的线程,等到计时时间到,此线程会自动苏醒.
	wait是Object类的方法,用于线程间的通信,这个方法会使当前拥有该对象锁的进程等待,直到其他线程调用notify方法才醒来,也可以指定时间自己醒来.
	对锁的处理机制不同
	由于sleep方法的主要作用是让线程休眠指定一段时间,在时间到时自动恢复,不涉及线程间的通信,因此,调用sleep方法并不会释放掉锁.
	但是调用wait方法的时候,线程会释放掉它所占用的锁,从而使线程所在对象中的其他synchronized数据可以被其他线程使用.
	使用的区域不同
	由于wait方法的特殊含义,所以它必须放在同步控制方法或者同步语句块中使用,而sleep方法则可以放在任何地方使用.
	异常的捕获
	sleep方法必须捕获异常,而wait,notify以及notifyall不需要捕获异常,在sleep的过程中,有可能别其他对象调用其interrupt(),产生InterruptedException异常.
	sleep不会释放锁标志,容易导致死锁的发生,所以一般情况下,不推荐使用sleep方法,而是使用wait方法.
#####31. 谈谈wait/notify关键字的理解
	先了解下wait 和 notify的作用：
	这两个方法的目的是为了避免自旋(或者说是等待)带来的性能损失。如果没有wait/notify，线程需要不停的轮询去查看某一条件是否达到了，这样就造成了CPU的浪费。而通过使用wait让线程挂起，等到条件运行完了再使用notify方法通知线程回复运行，这样就避免了CPU的浪费。
	wait/notify使用的时候需要配合synchronized一起使用，因为这两个方法是Object类中的方法，说明是基于对象而存在的，可能有多个线程一起调用这两个方法。所以无论是执行对象的wait、notify还是notifyAll方法，必须保证当前运行的线程取得了该对象的控制权（monitor），任何一个时刻，对象的控制权（monitor）只能被一个线程拥有
	调用wait()方法时，它可以让线程暂时放弃对象锁，将锁交给其他线程使用。其他线程使用完成之后调用notify/notifyAll方法唤醒一个或者多个线程(具体唤醒哪一个线程由操作系统的线程调度机制来决定)，继续执行后续的代码逻辑。
	但是如果notify代码执行在wait之前，线程就永远唤醒不了
#####33. 线程如何关闭？
	终止线程的三种方法
	1. 使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。while(flag)
	2. 使用stop方法强行终止线程（这个方法不推荐使用，因为stop和suspend、resume一样，也可能发生不可预料的结果）。
	3. 使用interrupt方法中断线程
	使用while（！isInterrupted（））{……}来判断线程是否被中断.
	interrupt()是一个“很软”的操作，也就是提醒线程应该结束了，至于如何结束，什么时候结束，以及是否需要结束，都是由线程自行处理。所以，interrupt()的使用，会让开发做更多的事，但这是有必要的，因为只有线程自己，才知道如何合适的结束自己
#####35. 数据一致性如何保证？
		synchronize lock atomic
#####40. Java中对象的生命周期
	1. 创建阶段（Created）
	在创建阶段系统通过下面的几个步骤来完成对象的创建过程
	为对象分配存储空间
	开始构造对象
	从超类到子类对static成员进行初始化
	超类成员变量按顺序初始化，递归调用超类的构造方法
	子类成员变量按顺序初始化，子类构造方法调用
	一旦对象被创建，并被分派给某些变量赋值，这个对象的状态就切换到了应用阶段
	2. 应用阶段（In Use）
	对象至少被一个强引用持有着。
	3.不可见阶段（Invisible）
	当一个对象处于不可见阶段时，说明程序本身不再持有该对象的任何强引用，虽然该这些引用仍然是存在着的。简单说就是程序的执行已经超出了该对象的作用域了。举例如下代码：本地变量 count 在打印时已经超出了其作用域，则在此时称之为 count 处于不可见阶段。当然这种情况编译器在编译的过程中会直接报错了。
	4. 不可达阶段（Unreachable）
	对象处于不可达阶段是指该对象不再被任何强引用所持有。与 “不可见阶段” 相比，“不可见阶段” 是指程序不再持有该对象的任何强引用，这种情况下，该对象仍可能被 JVM 等系统下的某些已装载的静态变量或线程或 JNI 等强引用持有着，这些特殊的强引用被称为 “GC root”。存在着这些 GC root 会导致对象的内存泄漏情况，无法被回收。
	5. 收集阶段（Collected）
	当垃圾回收器发现该对象已经处于 “不可达阶段” 并且垃圾回收器已经对该对象的内存空间重新分配做好准备时，则对象进入了 “收集阶段”。如果该对象已经重写了 finalize() 方法，则会去执行该方法的终端操作。这里要特别说明一下：不要重载 finazlie() 方法！原因有两点：会影响 JVM 的对象分配与回收速度
	在分配该对象时，JVM 需要在垃圾回收器上注册对象，以便在回收时能够执行该重载方法；在该方法的执行时需要消耗 CPU 时间且在执行完该方法后才会重新执行回收操作，即至少需要垃圾回收器对该对象执行两次 GC
	可能造成该对象的再次 “复活”在 finalize() 方法中，如果有其它的强引用再次持有该对象，则会导致对象的状态由 “收集阶段” 又重新变为 “应用阶段”。这个已经破坏了 Java 对象的生命周期进程，且 “复活” 的对象不利用后续的代码管理。
	6. 终结阶段（Finalized）
	当对象执行完 finalize() 方法后仍然处于不可达状态时，则该对象进入终结阶段。在该阶段是等待垃圾回收器对该对象空间进行回收。
	7. 对象空间重新分配阶段（De-allocated）
	垃圾回收器对该对象的所占用的内存空间进行回收或者再分配了，则该对象彻底消失了，称之为 “对象空间重新分配阶段”。
#####41. Synchronized用法 synchronize的原理
	Synchronized   monitorEnter monitorExit 指令对对象的对象头markWord修改，对象头1bit标识偏向锁状态，2bit标识同步状态。mutex锁修改状态。如果状态是加锁状态，其他线程挂起，重量级锁，是因为引起线程切换。1.6之后优化：
	Synchronized作用主要有三个：
	原子性：确保线程互斥的访问同步代码；
	可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的 “对一个变量unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操作初始化变量值” 来保证的；
	有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”；
	三种用法：
	当synchronized作用在实例方法时，监视器锁（monitor）便是对象实例（this）；
	当synchronized作用在静态方法时，监视器锁（monitor）便是对象的Class实例，因为Class数据存在于永久代，因此静态方法锁相当于该类的一个全局锁；
	当synchronized作用在某一个对象实例时，监视器锁（monitor）便是括号括起来的对象实例；
	实现机制：synchronized给出的答案是在软件层面依赖JVM，而j.u.c.Lock给出的答案是在硬件层面依赖特殊的CPU指令，monitorEnter monitorExit
	方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示符。JVM就是根据该标示符来实现方法的同步的
	当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象
	在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。
	实例数据：存放类的属性数据信息，包括父类的属性信息；
	对齐填充：由于虚拟机要求 对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐；
	对象头：Java对象头一般占有2个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit，在64位虚拟机中，1个机器码是8个字节，也就是64bit），但是 如果对象是数组类型，则需要3个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法从数组的元数据来确认数组的大小，所以用一块来记录数组长度。
	Mark Word用于存储对象自身的运行时数据，如：哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等。下图是Java对象头 无锁状态下Mark Word部分的存储结构（32位虚拟机）
	Monitor对象：通常说Synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是Monitor对象的起始地址。在Java虚拟机（HotSpot）中，Monitor是由ObjectMonitor实现的
	ObjectMonitor() {
    _header       = NULL;
    _count        = 0; // 记录个数
    _waiters      = 0,
    _recursions   = 0;
    _object       = NULL;
    _owner        = NULL;
    _WaitSet      = NULL; // 处于wait状态的线程，会被加入到_WaitSet
    _WaitSetLock  = 0 ;
    _Responsible  = NULL ;
    _succ         = NULL ;
    _cxq          = NULL ;
    FreeNext      = NULL ;
    _EntryList    = NULL ; // 处于等待锁block状态的线程，会被加入到该列表
    _SpinFreq     = 0 ;
    _SpinClock    = 0 ;
    OwnerIsThread = 0 ;
	  }
	  ObjectMonitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表（ 每个等待锁的线程都会被封装成ObjectWaiter对象 ），_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时
#####45. volatile的原理
	指令重排，JVM避免指令重排，支持内存屏障，happens-before原则，依赖，传递，以及volatile的规则，volatile变量规则：对一个volatile域的写，happens- before 于任意后续对这个volatile域的读。
	为了实施volatile对应的happens-before规则，对volatile变量的内存操作涉及到的内存屏障如下
	以volatile store -> volatile load为例，通过插入StroreLoad内存屏障，确保Store数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装载。从而实现，某个线程对volatile变量的修改会立即刷新到主内存，并导致其它线程工作内存中的副本无效，读取时只能从主内存加载最新的值。
	https://www.jianshu.com/p/933946794341
#####53. 死锁的四个必要条件？
	互斥条件。一个资源只能被一个进程占用
	不可剥夺条件。某个进程占用了资源，就只能他自己去释放。
	请求和保持条件。某个经常之前申请了资源，我还想再申请资源，之前的资源还是我占用着，别人别想动。除非我自己不想用了，释放掉。
	循环等待条件。一定会有一个环互相等待
#####55. 对象锁和类锁是否会互相影响？
	事实上，synchronized修饰非静态方法、同步代码块的synchronized (this)用法和synchronized (非this对象)的用法锁的是对象，线程想要执行对应同步代码，需要获得对象锁。
	synchronized修饰静态方法以及同步代码块的synchronized (类.class)用法锁的是类，线程想要执行对应同步代码，需要获得类锁
	需要特别说明：对于同一个类A，线程1争夺A对象实例的对象锁，线程2争夺类A的类锁，这两者不存在竞争关系。也就说对象锁和类锁互补干预内政
	静态方法则一定会同步，非静态方法需在单例模式才生效，但是也不能都用静态同步方法，总之用得不好可能会给性能带来极大的影响。另外，有必要说一下的是Spring的bean默认是单例的

###三、JVM
####3.1 基本概念
#####3.	什么是堆中的永久代（Perm Gen space）?
	metaspace perm 比较
	metaspace是分配在直接内存中（堆外），不指定大小的话，默认系统内存大小，直到耗尽内存。不参与垃圾回收，不会抛出perm OOM异常，但是如果指定了大小，超过最大大小，会触发GC
    PermGen的劣势
	•	固定的PermSize，大小很难确定并且很难进行扩展
	•	    -XX:MaxPermSize
	•	    -XX:PermSize
	•	在进行full GC时PermGen中的class meta对象有可能会被移动
	•	发生java.lang.OutOfMemoryError: PermGen error时
	•	    应用程序要清除与class关联的所有引用
	•	    要么更改MaxPermSize重启应用
	•	需要meta-classmeta对象对classmeta对象进行描述
	•		垃圾回收效率较低，需要进行对整个PermGen进行扫描
    Metaspace的优势
	•	类和类元数据的生命周期与类加载器一致
		•	Metaspace的空间分配是线性的，可随类加载的数量进行线性的扩展，默认情况下只与native memory大小有关
	•	元数据的位置在native memory中的位置是固定的
	•	GC时不会对metaspace空间进行扫描，节省了扫描和压缩的时间(如果设置了Metaspace的大小，当到达该Metaspace的阀值也会进行full GC)
	•	减小了full gc的时间
#####4.	说说各个区域的作用？
	程序计数器：是一块较小的内存空间，可以看做是当前线程所执行的字节码的行号指示器。由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个核心，或者一个处理器只会处理一个线程的某条指令。因此，线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。所以这个地方也不会出现OutOfMemoryError情况的区域。
	Java虚拟机栈：当每次调用一个方法的时候，其实就是在JVM内存上分配一个栈帧。这个栈帧包含一些局部变量表等信息。其中局部变量表所需的内存空间在编译期间就完成了分配。那针对这个区域规定了两种异常信息：第一种，如果栈请求的深度大于虚拟机所允许的深度，将抛出StackOverflowError 异常。第二种，如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。
	本地方法栈：主要为虚拟机使用到的native 方法服务。这部分在JVM的规范里面没有强制规定如何实现。与虚拟机栈一样，同样会抛出StackOverflowError和OutOfMemoryError 两种异常信息。
	Java堆：是被所有线程共享的一块内存区域，该内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都是在这里分配创建。由于他是虚拟机中管理的最大一块内存，所以是主要的收集区域。如果还需要再堆上分配实例，但是无法扩展出足够的内存空间，将会抛出OutOfMemoryError异常。
	方法区：也是各个线程共享的部分。主要用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。人们更愿意把这个部分称为“永久代”。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回收“成绩”比较难以令人满意。
#####10.	什么是tomcat类加载机制？
	https://www.jianshu.com/p/a18aecaecc89
	commonClassLoader CatalinaClassLoader WebAppClassLoader
#####14.	如何判断一个对象是否存活？
     GC Roots  
	1.虚拟机栈（本地变量表）引用的对象
	2.方法区静态属性引用的对象
	3.方法区常量引用的对象
	4.本地方法栈JNI（一般指naive方法）中引用的对象
#####16.	垃圾回收器的基本原理是什么？
	CMS  G1垃圾回收
    初始标记  并发标记 重新标记  并发清理
	G1垃圾回收器是主要针对多处理器以及大内存的机器，以极高的概率满足预测GC停顿时间要求的同时，还具备高吞吐量性能特征。是基于标记整理的垃圾回收器
	记忆集Rset https://www.jianshu.com/p/24a884fa3977
	https://www.jianshu.com/p/78e2d8579935
#####18.	深拷贝和浅拷贝？
	浅拷贝   引用类型，只是复制地址，改变会影响原件的变化
	深拷贝  真正的内容复制
#####19.	System.gc() 和 Runtime.gc() 会做些什么？
	java.lang.System.gc()只是java.lang.Runtime.getRuntime().gc()的简写，两者的行为没有任何不同
	•	System.gc()和runtime.gc()用于提示jvm进行垃圾回收，但是否立即回收还是延迟回收由java虚拟机决定
	System.gc(); //告诉垃圾收集器打算进行垃圾收集，而垃圾收集器进不进行收集是不确定的
	https://blog.csdn.net/qq_32534441/article/details/94989683
#####20.	什么是分布式垃圾回收（DGC）？它是如何工作的？
	DGC叫做分布式垃圾回收。RMI使用DGC来做自动垃圾回收。因为RMI包含了跨虚拟机的远程对象的引用，垃圾回收是很困难的。DGC使用引用计数算法来给远程对象提供自动内存管理。
	RMI 子系统实现基于引用计数的“分布式垃圾回收”(DGC)，以便为远程服务器对象提供自动内存管理设施。
	当客户机创建（序列化）远程引用时，会在服务器端 DGC 上调用 dirty()。当客户机完成远程引用后，它会调用对应的 clean() 方法。
	针对远程对象的引用由持有该引用的客户机租用一段时间。租期从收到 dirty() 调用开始。在此类租约到期之前，客户机必须通过对远程引用额外调用 dirty() 来更新租约。如果客户机不在租约到期前进行续签，那么分布式垃圾收集器会假设客户机不再引用远程对象
#####22.	在 Java 中，对象什么时候可以被垃圾回收？
	无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析判断对象的引用链是否可达，判断对象是否存活都与“引用”有关。
	在 JDK 1.2 之后，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference） 4 种，这 4 种引用强度一次逐渐减弱。
	•	强引用就是指在程序代码之中普遍存在的，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。
	•	软引用是用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前（即内存紧张）， 将会把这些对象列进垃圾回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在 JDK1.2 之后， 提供了 SoftReference 类累实现软引用。
	•	弱引用是用来描述非必需的对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。 当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。使用 WeekReference 类来实现弱引用。
	•	虚引用也成为幽灵引用或者幻影引用，它是最弱的一种引用。一个对象是否有虚引用的存在，完全不会对其生存周期时间构成影响， 也无法通过虚引用来取得一个对象实例。唯一的作用就是能在这个对象被收集器回收时收到一个系统通知。使用 PhantomReference 表示。
#####26.	常用的性能优化方式有哪些？
	https://www.jianshu.com/p/f57d05247329
	从以下几个方面：
	JAVA代码层面、数据库、架构、缓存、异步等

###四、数据库
####1.基本概念
#####1.	MySQL 有哪些存储引擎啊？都有什么区别？
	innoDB  MYISAM	
#####2.	Float、Decimal 存储金额的区别？
	https://www.jianshu.com/p/40bddd5126f9
	Float 二进制 精度6~7位，可能不准确 性能高
	Decimal 十进制保存，更高精度 28位，但性能差
#####5.	对比一下B+树索引和 Hash索引？
	简单地说，哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。
	从上面的图来看，B+树索引和哈希索引的明显区别是：
	如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
	从示意图中也能看到，如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
	同理，哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
	哈希索引也不支持多列联合索引的最左匹配规则；
	B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。
	通常，B+树索引结构适用于绝大多数场景，像下面这种场景用哈希索引才更有优势：
	在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引
#####6.	MySQL索引类型有？
	https://www.jianshu.com/p/25911c72f91c
	普通索引、唯一索引、主键索引、联合索引、全文索引
#####8.	对Explain参数及重要参数的理解？
	key  extends  rows
	expain出来的信息有10列，分别是id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra,下面对这些字段出现的可能进行解释：
	一、 id
     我的理解是SQL执行的顺序的标识,SQL从大到小的执行
	1. id相同时，执行顺序由上至下
	2. 如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行
	3.id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行
	二、select_type 标示查询中每个select子句的类型	
	(1) SIMPLE(简单SELECT,不使用UNION或子查询等)
	(2) PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY)
	(3) UNION(UNION中的第二个或后面的SELECT语句)
	(4) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)
	(5) UNION RESULT(UNION的结果)
	(6) SUBQUERY(子查询中的第一个SELECT)
	(7) DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询)
	(8) DERIVED(派生表的SELECT, FROM子句的子查询)
	(9) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)
	四、type 表示MySQL在表中找到所需行的方式，又称“访问类型”。
	常用的类型有： ALL, index,  range, ref, eq_ref, const, system, NULL（从左到右，性能从差到好）
	ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行
	index: Full Index Scan，index与ALL区别为index类型只遍历索引树
	range:只检索给定范围的行，使用一个索引来选择行
	ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
	eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件
	const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system
	NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
	五、possible_keys
	指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用
	该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。
	如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询
	六、Key
	key列显示MySQL实际决定使用的键（索引）
	如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。
	七、key_len
	表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度（key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的）
	不损失精确性的情况下，长度越短越好 
	八、ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值
	九、rows 表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数
	十、Extra
	该列包含MySQL解决查询的详细信息,有以下几种情况：
	Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤
	Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询
	Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”
	Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。
	Impossible where：这个值强调了where语句会导致没有符合条件的行。
	Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行
#####10.	聚簇索引和非聚簇索引的区别？
	聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据
	非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因
#####11.	B+tree 如何进行优化？索引遵循哪些原则？
	一、离散型
	二、最左匹配
	三、联合索引
	四、覆盖索引
#####12.索引与锁有什么关系
	https://www.jianshu.com/p/42c3e34a3367Mysql
		索引使用的数据结构主要有BTree索引 和 哈希索引 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。Mysql的BTree索引使用的是B树中的B+Tree，但对于主要的两种存储引擎的实现方式是不同的。MyISAM: B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。InnoDB: 其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”。而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。锁 MyISAM和InnoDB存储引擎使用的锁：
	MyISAM采用表级锁(table-level locking)。
	InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁
表级锁和行级锁对比：
	•	表级锁： Mysql中锁定 粒度最大 的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和 InnoDB引擎都支持表级锁。
•	行级锁： Mysql中锁定 粒度最小 的一种锁，只针对当前操作的行进行加锁。 行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。
	InnoDB存储引擎的锁的算法有三种：
•	Record lock：单个行记录上的锁 
•	Gap lock：间隙锁，锁定一个范围，不包括记录本身 
•	Next-key lock：record+gap 锁定一个范围，包含记录本身 相关知识点：
1.	innodb对于行的查询使用next-key lock
2.	Next-locking keying为了解决Phantom Problem幻读问题
3.	当查询的索引含有唯一属性时，将next-key lock降级为record key
4.	Gap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生
5.	有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1
	innodb 的锁是基于索引做的
#####14.	谈谈对Innodb事务的理解？
	https://www.jianshu.com/p/9b83ea78b380
	redoLog undoLog
	redo log 通常是 物理 日志，记录的是 数据页 的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页(恢复数据页，且只能恢复到最后一次提交的位置)。
	2.undo log 用来回滚行记录到某个版本。undo log 一般是逻辑日志，根据每行记录进行记录。
	Undo 记录某 数据 被修改 前 的值，可以用来在事务失败时进行 rollback；
	Redo 记录某 数据块 被修改 后 的值，可以用来恢复未写入 data file 的已成功事务更新的数据。
	Redo Log 保证事务的持久性
	Undo Log 保证事务的原子性（在 InnoDB 引擎中，还用 Undo Log 来实现 MVCC）
	比如某一时刻数据库 DOWN 机了，有两个事务，一个事务已经提交，另一个事务正在处理。数据库重启的时候就要根据日志进行前滚及回滚，把已提交事务的更改写到数据文件，未提交事务的更改恢复到事务开始前的状态。即，当数据 crash-recovery 时，通过 redo log 将所有已经在存储引擎内部提交的事务应用 redo log 恢复，所有已经 prepared 但是没有 commit 的 transactions 将会应用 undo log 做 roll back。
	redo/undo log 和 binlog
	两者区别还是挺多的，大致如下，
	层次不同。redo/undo 是 innodb 引擎层维护的，而 binlog 是 mysql server 层维护的，跟采用何种引擎没有关系，记录的是所有引擎的更新操作的日志记录。
	记录内容不同。redo/undo 记录的是 每个页/每个数据 的修改情况，属于物理日志+逻辑日志结合的方式（redo log 是物理日志，undo log 是逻辑日志）。binlog 记录的都是事务操作内容，binlog 有三种模式：Statement（基于 SQL 语句的复制）、Row（基于行的复制） 以及 Mixed（混合模式）。不管采用的是什么模式，当然格式是二进制的，
	记录时机不同。redo/undo 在 事务执行过程中 会不断的写入，而 binlog 是在 事务最终提交前 写入的。binlog 什么时候刷新到磁盘跟参数 sync_binlog 相关。
	binlog 三种模式对比
	上面提到 binlog 有三种格式，各有优缺点：
	statement：基于SQL语句的模式，某些语句中含有一些函数，例如 UUID NOW 等在复制过程可能导致数据不一致甚至出错。
	row：基于行的模式，记录的是行的变化，很安全。但是 binlog 的磁盘占用会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。
	mixed：混合模式，根据语句来选用是 statement 还是 row 模式
#####15.	说说数据库事务特点及潜在问题？
	ACID 
#####16.	什么是MySQL隔离级别？
	读未提交Read uncommitted
	该隔离级别下，所有事务都可以读取到其他事务没有提交的处理结果。很少用于实际应用，因为不能保证数据的一致性。
	读已提交Read committed
	大多数数据库采用的默认隔离级别，如Oracle。读已提交隔离级别下，读取不加锁，写加锁，即数据的删除、修改及写入都需要加锁，使得事务只能看到其他事务已经提交的数据，避免了脏读。
	可重复读Repeated read
	解决脏读和不可重复读的数据不一致性问题，保证同一事务的多个实例访问数据时，读到的结果是一致的。
	串行化Serializable
	完全串行化，读操作加锁，写操作加锁，读写锁互相阻塞。这个隔离级别下，可能会造成大量的超时以及锁竞争现象。

#####17.	有多少种事务失效的场景，如何解决？
	1、数据库引擎不支持事务
	这里以 MySQL 为例，其 MyISAM 引擎是不支持事务操作的，InnoDB 才是支持事务的引擎，一般要支持事务都会使用 InnoDB。
	2、没有被 Spring 管理
	这个类就不会被加载成一个 Bean，那这个类就不会被 Spring 管理了，事务自然就失效了。
	3、方法不是 public 的
	大概意思就是 @Transactional 只能用于 public 的方法上，否则事务不会失效，如果要用在非 public 方法上，可以开启 AspectJ 代理模式。
	4、自身调用问题
	因为它们发生了自身调用，就调该类自己的方法，而没有经过 Spring 的代理类，默认只有在外部调用事务才会生效，这也是老生常谈的经典问题了。
	这个的解决方案之一就是在的类中注入自己，用注入的对象再调用另外一个方法，这个不太优雅，另外一个可行的方案可以参考《Spring 如何在一个事务中开启另一个事务？》这篇文章。
	5、数据源没有配置事务管理器
	@Bean
	public PlatformTransactionManager transactionManager(DataSource dataSource) {
    return new DataSourceTransactionManager(dataSource);
	}
	如上面所示，当前数据源若没有配置事务管理器，那也是白搭！
	6、不支持事务 Propagation.NOT_SUPPORTED： 表示不以事务运行，当前若存在事务则挂起，详细的可以参考《事务隔离级别和传播机制》这篇文章。
	都主动不支持以事务方式运行了，那事务生效也是白搭！
	7、异常被吃了
	8、异常类型错误
	默认回滚的是：RuntimeException，如果你想触发其他异常的回滚，需要在注解上配置一下，如：
	@Transactional(rollbackFor = Exception.class)
	这个配置仅限于 Throwable 异常类及其子类。
#####19.	Innodb如何解决幻读？
	InnoDB默认的隔离级别是RR（可重复读），可以解决脏读和不可重复读，但是不能解决幻读问题。什么是幻读？事务A读取了一个范围内的数据，此时事务B在该范围内插入了一条数据，并立马提交了事务，此时事务A再次读取这个范围的数据时，发现多了一条，就好像幻觉一样。
	什么是MVCC？
	多版本并发控制。InnoDB为每行记录添加了一个版本号（系统版本号），每当修改数据时，版本号加一。
	在读取事务开始时，系统会给事务一个当前版本号，事务会读取版本号<=当前版本号的数据，这时就算另一个事务插入一个数据，并立马提交，新插入这条数据的版本号会比读取事务的版本号高，因此读取事务读的数据还是不会变。
	https://www.jianshu.com/p/70816d3c244c
	https://www.cnblogs.com/fanguangdexiaoyuer/p/10759746.html
	总结：
	Mysql 默认RR级别   传统的RR是避免不可重复读，但不能避免幻读，mysql通过MVCC 避免不可重复度，MVCC的间隙锁 避免幻读
#####20.	讲讲Innodb行锁？
	InnoDB中行锁有三种分别是，
	record lock：单个行记录上的锁
	gap lock：间隙锁，锁定一个范围，但不锁定记录本身。间隙锁只会阻塞间隙间的数据插入(insert)。多个间隙锁获取操作不冲突。
	next-key lock：record lock+gap lock，前开后闭的区间。
	InnoDB通过给索引项上的索引加锁来实现行锁。这也意味着只有通过索引条件检索数据才会被加上行锁，否则InnoDB将使用表锁。
	索引不仅包括主键索引，普通索引、唯一索引都可以使用行锁
	只有真正执行计划用到的索引才会被加锁，条件里面包含索引列的语句在执行时不一定会用到索引，可使用explain分析具体的执行情况
	select语句显式加锁：
	//共享锁（读锁） select ... lock in share mode
	//互斥锁（写锁） select ... for update
	更新操作（update）和插入（insert）操作会自动加锁
	加锁规则：
	1.加锁基本单位是next-key lock，即前开后闭区间
	2.查找过程中访问到的对象才会加锁
	3.索引上的等值查询，给唯一索引加锁时，next-key lock退化为行锁
	4.索引上的等值查询，向右遍历时且最右一个值不满足等值条件的时候，next-key lock退化为间隙锁
	https://www.jianshu.com/p/7171f5aa26d1
#####24.	高并发场景（领红包）如何防止死锁，保证数据一致性？
	乐观锁，悲观锁
	避免死锁
	在有些情况下死锁是可以避免的。三种用于避免死锁的技术：
	加锁顺序（线程按照一定的顺序加锁）
	加锁时限（线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁）
	死锁检测
	死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。
	每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。
	当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。例如，线程A请求锁7，但是锁7这个时候被线程B持有，这时线程A就可以检查一下线程B是否已经请求了线程A当前所持有的锁。如果线程B确实有这样的请求，那么就是发生了死锁（线程A拥有锁1，请求锁7；线程B拥有锁7，请求锁1）
#####25.	谈谈MySQL的锁并发？
	IS：若要对一个节点加S锁，先要对其父节点加IS锁，表明它的子节点有意向加S锁。
	IX: 若要对一个节点加X锁，先要对父节点加IX锁，表明它的子节点有意向加X锁。
	有什么好处
	避免不必要的检查目标节点的锁状态，比如发现某张表没能获得意向锁，说明有人在用，事务会等待意向锁的释放，而不是固执地一行一行去检查行有没有被上锁， 避免加锁解锁开销。
#####26 Count 相关
	从执行结果来说：
	count（1）和count（*）之间没有区别，因为count（*）count（1）都不会去过滤空值，
	但count（列名）就有区别了，因为count（列名）会去过滤空值。
	从执行效率来说：
	 他们之间根据不同情况会有些许区别，MySQL会对count（*）做优化。

         （1）如果列为主键，count(列名)效率优于count(1)  

         （2）如果列不为主键，count(1)效率优于count(列名)  

         （3）如果表中存在主键，count(主键列名)效率最优  

         （4）如果表中只有一列，则count(*)效率最优  

          （5）如果表有多列，且不存在主键，则count(1)效率优于count(*)

	补充关于count（1）count（*）原理 引用百度知道专业回答
	count(1)，其实就是计算一共有多少符合条件的行。
	1并不是表示第一个字段，而是表示一个固定值。
	其实就可以想成表中有这么一个字段，这个字段就是固定值1，count(1)，就是计算一共有多少个1.
	count(*)，执行时会把星号翻译成字段的具体名字，效果也是一样的，不过多了一个翻译的动作，比固定值的方式效率稍微低一些。

###五、缓存
####1. 基本概念
#####1.	redis数据结构有哪些？
        字符串（string）列表（list）字典（hash）集合（set）有序集合（zset）
#####2.	Redis缓存穿透，缓存雪崩？
	缓存击穿表示恶意用户模拟请求很多缓存中不存在的数据，由于缓存中都没有，导致这些请求短时间内直接落在了数据库上，导致数据库异常。这个我们在实际项目就遇到了，有些抢购活动、秒杀活动的接口API被大量的恶意用户刷，导致短时间内数据库c超时了，好在数据库是读写分离，同时也有进行接口限流，hold住了。
	解决方案的话：
	方案1、使用互斥锁排队
	业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中load数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。这里要注意，分布式环境中要使用分布式锁，单机的话用普通的锁（synchronized、Lock）就够了。
	方案2、接口限流与熔断、降级
	重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。
	方案3、布隆过滤器
	缓存雪崩问题
	缓存在同一时间内大量键过期（失效），接着来的一大波请求瞬间都落在了数据库中导致连接异常。
	解决方案：
	方案1、也是像解决缓存穿透一样加锁排队，实现同上;
	方案2、建立备份缓存，缓存A和缓存B，A设置超时时间，B不设值超时时间，先从A读缓存，A没有读B，并且更新A缓存和B缓存;
	方案3、设置缓存超时时间的时候加上一个随机的时间长度，比如这个缓存key的超时时间是固定的5分钟加上随机的2分钟，酱紫可从一定程度上避免雪崩问题；
#####3.	如何使用Redis来实现分布式锁？
	分布式锁三种实现方式：
	1. 基于数据库实现分布式锁；
	2. 一， 基于数据库实现分布式锁
	1. 悲观锁
	利用select … where … for update 排他锁
	注意: 其他附加功能与实现一基本一致，这里需要注意的是“where name=lock ”，name字段必须要走索引，否则会锁表。有些情况下，比如表不大，mysql优化器会不走这个索引，导致锁表问题。
	2. 乐观锁
	所谓乐观锁与前边最大区别在于基于CAS思想，是不具有互斥性，不会产生锁等待而消耗资源，操作过程中认为不存在并发冲突，只有update version失败后才能觉察到。我们的抢购、秒杀就是用了这种实现以防止超卖。
	2. 基于缓存（Redis等）实现分布式锁；
	3. 二， 基于缓存（Redis等）实现分布式锁
	1. 使用命令介绍：
	（1）SETNX
	SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。
	（2）expire
	expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。
	（3）delete
	delete key：删除key
	在使用Redis实现分布式锁的时候，主要就会使用到这三个命令。
	2. 实现思想：
	（1）获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。
	（2）获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。
	（3）释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。
	3. 基于Zookeeper实现分布式锁；
	4. ZooKeeper是一个为分布式应用提供一致性服务的开源组件，它内部是一个分层的文件系统目录树结构，规定同一个目录下只能有一个唯一文件名。基于ZooKeeper实现分布式锁的步骤如下：
	（1）创建一个目录mylock；
	（2）线程A想获取锁就在mylock目录下创建临时顺序节点；
	（3）获取mylock目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；
	（4）线程B获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；
	（5）线程A处理完，删除自己的节点，线程B监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。
		这里推荐一个Apache的开源库Curator，它是一个ZooKeeper客户端，Curator提供的InterProcessMutex是分布式锁的实现，acquire方法用于获取锁，release方法用于释放锁。
	优点：具备高可用、可重入、阻塞锁特性，可解决失效死锁问题。
	缺点：因为需要频繁的创建和删除节点，性能上不如Redis方式。
	四，对比
	数据库分布式锁实现
	缺点：
	1.db操作性能较差，并且有锁表的风险
	2.非阻塞操作失败后，需要轮询，占用cpu资源;
	3.长时间不commit或者长时间轮询，可能会占用较多连接资源
	Redis(缓存)分布式锁实现
	缺点：
	1.锁删除失败 过期时间不好控制
	2.非阻塞，操作失败后，需要轮询，占用cpu资源;
	ZK分布式锁实现
	缺点：性能不如redis实现，主要原因是写操作（获取锁释放锁）都需要在Leader上执行，然后同步到follower。
	总之：ZooKeeper有较好的性能和可靠性。
	从理解的难易程度角度（从低到高）数据库 > 缓存 > Zookeeper
	从实现的复杂性角度（从低到高）Zookeeper >= 缓存 > 数据库
	从性能角度（从高到低）缓存 > Zookeeper >= 数据库
	从可靠性角度（从高到低）Zookeeper > 缓存 > 数据库
#####5.	Redis持久化的几种方式，优缺点是什么，怎么实现的？
	Redis 的读写都是在内存中，所以它的性能较高，但在内存中的数据会随着服务器的重启而丢失，为了保证数据不丢失，我们需要将内存中的数据存储到磁盘，以便 Redis 重启时能够从磁盘中恢复原有的数据，而整个过程就叫做 Redis 持久化。
	Redis 持久化拥有以下三种方式：
	快照方式（RDB, Redis DataBase）将某一个时刻的内存数据，以二进制的方式写入磁盘；
	文件追加方式（AOF, Append Only File），记录所有的操作命令，并以文本的形式追加到文件中；
	混合持久化方式，Redis 4.0 之后新增的方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能简单数据丢失的风险。
#####6.	Redis的缓存失效策略？
	FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。
	LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。
	LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。
#####7.	Redis集群，高可用，原理？
	REDIS集群的几个重要特征
	(1).Redis 集群的分片特征在于将键空间分拆了16384个槽位，每一个节点负责其中一些槽位。 (2).Redis提供一定程度的可用性,可以在某个节点宕机或者不可达的情况下继续处理命令. (3).Redis 集群中不存在中心(central)节点或者代理(proxy)节点， 集群的其中一个主要设计目标是达到线性可扩展性(linear scalability)。
	集群客户端连接集群中任一Redis Instance即可发送命令，当Redis Instance收到自己不负责的Slot的请求时，会将负责请求Key所在Slot的Redis Instance地址返回给客户端，客户端收到后自动将原请求重新发往这个地址，对外部透明。一个Key到底属于哪个Slot由crc16(key) % 16384 决定。
	REDIS数据切片
	Redis 集群的键空间被分割为 16384 (2^14)个槽(slot)， 集群的最大节点数量也是 16384 个(推荐的最大节点数量为 1000 个)，同理每个主节点可以负责处理1到16384个槽位。当16384个槽位都有主节点负责处理时，集群进入“稳定”上线状态，可以开始处理数据命令。当集群没有处理稳定状态时，可以通过执行重配置(reconfiguration)操作，使得每个哈希槽都只由一个节点进行处理。 重配置指的是将某个/某些槽从一个节点移动到另一个节点。一个主节点可以有任意多个从节点， 这些从节点用于在主节点发生网络断线或者节点失效时， 对主节点进行替换。 集群的使用公式HASH_SLOT=CRC16(key) mod 16384 计算key属于哪个槽。CRC16其结果长度为16位。
	REDIS集群的原理是什么？
	Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储
#####8.	Redis缓存分片？
	Redis集群的分片存储是在Redis3.0以后推出的架构方案。整个架构如下
	1.在整个集群中，Redis会对每台机器分配一段槽位-solt,总共有16384个槽位（0-16383），也就是我们的集群最多可以是16384太机器,集群中节点之间会互相交换节点信息，传递消息，包括槽位的信息，如果集群过大，交互的信息会很多，会带来带宽的消耗，所以Redis官方建议最大1000个实例。
	2.Redis-server接受到一条数据是，会通过key进行hash计算，确认槽位，这里有点类似concurrentHashMap的操作，确定一个segment后才去操作
	3.发送数据到集群的任何一台机器，如果不是槽位不匹配，服务端会做重定向的返回信息
	4.客户端可以缓存集群信息，减少与服务端的网络开销，当集群扩容是，会对新的机器分配一段槽位(注意这里是将16384进行调整，分配一段到新的机器)
	如何避免节点数据倾斜
	1.前期规划key,解决热点数据的问题
	2.slot槽位迁移
#####10.	redis队列应用场景？
       消息队列
#####11.	分布式使用场景（储存session）？
	略
###六、网络编程
####1.基本概念
#####1.	TCP建立连接和断开连接的过程？
     三次握手
     四次挥手
#####2.	HTTP协议的交互流程，HTTP和HTTPS的差异，SSL的交互流程？
	HTTP 的缺点
	通信使用明文（不加密），内容可能会被窃听
	不验证通信方的身份，因此有可能遭遇伪装
	无法证明报文的完整性，所以有可能已遭篡改
	Hypertext Transfer Protocol over Secure Socket Layer，是以安全为目标的HTTP通道，简单讲是HTTP的安全版。即HTTP下加入TLS层，HTTPS的安全基础是TLS。
	所以相比HTTP，HTTPS 传输更加安全
	（1） 所有信息都是加密传播，黑客无法窃听。
	（2） 具有校验机制，一旦被篡改，通信双方会立刻发现。
	（3） 配备身份证书，防止身份被冒充。
	HTTPS 缺点：
	SSL 证书费用很高，以及其在服务器上的部署、更新维护非常繁琐
	HTTPS 降低用户访问速度（多次握手）
	网站改用HTTPS 以后，由HTTP 跳转到 HTTPS 的方式增加了用户访问耗时（多数网站采用302跳转）
	HTTPS 涉及到的安全算法会消耗 CPU 资源，需要增加大量机器（https访问过程需要加解密）
	如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。
	如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密
	浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比
	对比结果一致，则证明服务器发来的证书合法，没有被冒充
	此时浏览器就可以读取证书中的公钥，用于后续加密了
#####7.	webservice协议（wsdl/soap格式，与restt办议的区别）？


###七、分布式
####1.基本概念
#####1.	什么是CAP定理？
	Consisteny（一致性）
	Availability（可用性）
	Partition tolerance（分区容错性）
	Eric Brewer在提出CAP概念的同时，也证明了CAP定理：任何分布式系统在可用性、一致性、分区容忍性方面，不可能同时被满足，最多只能得其二。该定理也被称作布鲁尔定理
#####2.	说说CAP理论和BASE理论？
	对于很多互联网应用来说，对一致性的要求可以降低，而可用性的要求则更为重要，从而产生了弱一致性的BASE理论。BASE理论是基于CAP理论逐步演化而来的，其核心思想是即使不能达到强一致性，也可以根据应用特点采用适当的方法来达到最终一致性的效果。BASE是Basically Available（基本可用）、Soft state（软状态/柔性状态）、Eventually consistent（最终一致性）三个词组的简写，是对CAP中C和A的延伸
	BASE理论的含义如下：
	基本可用：在绝大多数时间内系统处于可用状态，允许偶尔的失败。
	软状态/柔性状态：数据状态不要求在任意时刻都完全保持同步，即状态可以有一段时间不同步。
	最终一致性：与强一致性相比，最终一致性是一种弱一致性。尽管软状态不要求任意时刻数据保持一致同步，但是最终一致性要求在给定时间窗口内数据会达到一致状态。
	以上就是BASE理论的基本概念，可见BASE理论强调的是系统的高可用，允许系统在一定时间内存在数据不一致，但在给定的时间窗口内，系统最终一定是要达到一致状态的
#####5.	讲讲分布式事务？
	事务的操作位于不同的节点，不同的数据库上，要保持事务的ACID特性。  模块的拆分，服务的独立部署等，带来分布式事务问题。
	https://www.jianshu.com/p/3aea2f91a266
	CAP理论和BASE理论
	BASE理论是对CAP理论的延伸，核心思想是即使无法做到强一致性（Strong Consistency，CAP的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性（Eventual Consitency）
	BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。
	BA：（Basically Available ），基本可用。
	基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。
	S：（ Soft State），软状态
	软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。
	E：（Eventually Consistent ），最终一致 
	最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。
	弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。
	ACID是传统数据库常用的设计理念，追求强一致性模型。BASE支持的是大型分布式系统，提出通过牺牲强一致性获得高可用性
	方案一：事务消息
	方案二：补偿事务  TCC
	方案三：二阶段协议   2PC ：fascar 更名为seata  3PC   底层数据库接口都遵循XA规范  perpare  commit rollback
	2PC和3PC的比较 https://www.jianshu.com/p/dd6a340e50b2
	二阶段提交还是有几个缺点的：
	1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。
	2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）
	3、数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。
	4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。
	与两阶段提交不同的是，三阶段提交有两个改动点。
	1、引入超时机制。同时在协调者和参与者中都引入超时机制。
	2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
	https://blog.csdn.net/huaishu/article/details/93046220
#####9.	负载均衡的理解？
	Dubbo 比较经典的5种负载均衡算法：随机法、轮询法、最少连接数法、最快响应法、Hash化散列法（包括IP-Hash和参数值Hash一致性算法），另外还可以整合权重（配置权重值和JVM预热启动加权）
	随机法：实现比较简单，也不需要记住状态位，每次随机选举，实现负载均衡的同时又避免了在选取节点时候的复杂运算
	轮询法：实现更公平的负载均摊，但是是基于所有访问的服务器处理响应时间差不多的业务场景
	最少连接数法：实现了更贴合实际场景的负载均摊，真正实现了根据服务器的实际处理能力来分摊请求，避免了慢堆积
	通过统计每个Server的平均响应时间，然后选取最快的server，可以实现动态的调整负载的均摊。
	Hash化散列法：IP哈希可以解决集群的Session共享问题，Hash一致性解决的是在非常复杂的集群模式下，频繁发生节点的新增和删除的时候，如何实现影响最小的请求均摊。
	权重值的引入，非常有意义的一个干预参数，因为实际的业务场景，每台服务器的物理环境所导致的服务性能各不相同。可以和随机法、轮训法、最少连接数法结合起来用，在和轮询法结合起来用时，又有平滑的负载均摊和不是很平滑的负载均摊。
	nginx Nginx目前有5种负载均衡配置：
	round_robin，加权轮询，是默认的HTTP负载均衡算法，适用于知道机器的性能，且默认所有的请求对于服务器而言，处理的时间相差不大。比如我Server1 比Server2的配置要高一倍，我设置为2:1的权重，可以实现比较科学的负载。算法实现上，简单的轮询很简单，给每个Server依次编号，然后只要记录一个调用index，既可以实现轮询。
	ip_hash，IP哈希，可保持会话
	least_conn; 避免了慢堆积，会取连接数最小的server提供服务，可以避免有些请求耗时长，有些耗时端的情况。根据实际的连接数选择服务器。
	fair，需要插件扩展该功能，根据后端服务器的响应时间来分配请求，响应时间短的优先分配，避免慢堆积。
			权重配置：而且采用的是平滑的负载均衡算法，比如node1:node2:node3=1:2:5 --node3，node3，node2，node3，node1，node3，node2，node3
#####10.	正向代理和反向代理？
#####11.	CDN实现原理？
#####12.	怎么提升系统的QPS和吞吐？
	集群+负载均衡
	增加缓存
	系统拆分
	分库分表
	垂直拆分+水平拆分
	异步化+MQ
#####13.	Dubbo的底层实现原理和机制？
	作为RPC:支持各种传输协议，如dubbo,hession,json,fastjson，底层采用mina,netty长连接进行传输！典型的provider和cusomer模式!
	作为SOA:具有服务治理功能，提供服务的注册和发现！用zookeeper实现注册中心！启动时候服务端会把所有接口注册到注册中心，并且订阅configurators,服务消费端订阅provide，configurators,routers,订阅变更时，zk会推送providers,configuators，routers,启动时注册长连接，进行通讯！proveider和provider启动后，后台启动定时器，发送统计数据到monitor！提供各种容错机制和负载均衡策略
#####14.	描述一个服务从发布到被消费的详细过程？
#####15.	分布式系统怎么做服务治理？
#####16.	消息中间件如何解决消息丢失问题？
#####17.	Dubbo的服务请求失败怎么处理？
#####18.	对分布式事务的理解？
#####19.	如何实现负载均衡,有哪些算法可以实现?
#####20.	Zookeeper的用途,选举的原理是什么?
#####21.	讲讲数据的垂直拆分水平拆分？
#####22.	zookeeper原理和适用场景？
#####23.	zookeeper watch机制？
#####24.	redis/zk节点宕机如何处理？
#####25.	分布式集群下如何做到唯一序列号？
#####26.	用过哪些MQ,怎么用的,和其他mq比较有什么优缺点,MQ的连接是线程安全的吗？
#####27.	MQ系统的数据如何保证不丢失？

#####28.	列举出能想到的数据库分库分表策略？

#####29.	Zookeeper实现原理，以及选主算法

#####30.	为什么需要配置中心，配置中心如何实现的

#####分布式事务，两阶段提交。


#####如何实现分布式锁
	使用分布式锁，和乐观锁的区别？
	多表关联同时更新的情况，乐观锁容易出现死锁，数据库开销大
	简单来说，有以下几种方案：
	一、数据库，加X排它锁，select for update ；或者利用数据库的唯一键，能插入唯一键，线程即获得锁
	二、ZK
	先有一个锁跟节点，lockRootNode，这可以是一个永久的节点
	客户端获取锁，先在lockRootNode下创建一个顺序的瞬时节点，保证客户端断开连接，节点也自动删除
	调用lockRootNode父节点的getChildren()方法，获取所有的节点，并从小到大排序，如果创建的最小的节点是当前节点，则返回true,获取锁成功，否则，关注比自己序号小的节点的释放动作(exist watch)，这样可以保证每一个客户端只需要关注一个节点，不需要关注所有的节点，避免羊群效应。
	如果有节点释放操作，重复步骤3 ###释放锁 只需要删除步骤2中创建的节点即可
	三、缓存 redis tair
	利用setNx，key为null的时候才设置成功，返回1，其他返回0；注意点：
	1）超时时间设置，避免宕机或者超时等异常导致锁一致被无法释放（缓存没法delete） 2）如果要实现可重入，设置count计数 3）避免超时等异常导致锁被其他线程占用之后，释放锁的时候，释放了其他线程的锁，可加入每个请求唯一id，作为缓存value，只有请求id是当前线程的请求id，才可以删除缓存，释放锁。
#####如何实现分布式Session
#####如何保证消息的一致性
#####负载均衡
#####正向代理（客户端代理）和反向代理（服务器端代理）
#####CDN实现原理
#####怎么提升系统的QPS和吞吐量
#####DNS的实现原理
#####介绍下PAXOS协议
#####介绍下Zookeeper的ZAB协议，如何选举LEADER？如何

#####27.	说说分布式缓存和一致性哈希？

###八、JDK基础
####1. java基础面试知识点
#####1. Transient关键字
#####2.Ierator 和 Enumeration 比较
	https://www.jianshu.com/p/e1bed6c84c04
	在Java集合中，我们通常都通过 “Iterator(迭代器)” 或 “Enumeration(枚举类)” 去遍历集合。今天，我们就一起学习一下它们之间到底有什么区别。
	我们先看看 Enumeration.java 和 Iterator.java的源码，再说它们的区别。
	Enumeration是一个接口，它的源码如下：
	Iterator也是一个接口，它的源码如下：
	看完代码了，我们再来说说它们之间的区别。
	(01) 函数接口不同
	Enumeration只有2个函数接口。通过Enumeration，我们只能读取集合的数据，而不能对数据进行修改。
	Iterator只有3个函数接口。Iterator除了能读取集合的数据之外，也能数据进行删除操作。
	(02) Iterator支持fail-fast机制，而Enumeration不支持。
	Enumeration 是JDK 1.0添加的接口。使用到它的函数包括Vector、Hashtable等类，这些类都是JDK 1.0中加入的，Enumeration存在的目的就是为它们提供遍历接口。Enumeration本身并没有支持同步，而在Vector、Hashtable实现Enumeration时，添加了同步。
	而Iterator 是JDK 1.2才添加的接口，它也是为了HashMap、ArrayList等集合提供遍历接口。Iterator是支持fail-fast机制的：当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。
	第2部分 Iterator和Enumeration实例
	下面，我们编写一个Hashtable，然后分别通过 Iterator 和 Enumeration 去遍历它，比较它们的效率。代码如下：

	从中，我们可以看出。Enumeration 比 Iterator 的遍历速度更快。为什么呢？
	这是因为，Hashtable中Iterator是通过Enumeration去实现的，而且Iterator添加了对fail-fast机制的支持；所以，执行的操作自然要多一些。

#####3. java是值传递的
	在Java中所有的参数传递，不管基本类型还是引用类型，都是值传递，或者说是副本传递。只是在传递过程中如果是对基本数据类型的数据进行操作，由于原始内容和副本都是存储实际值，并且是在不同的栈区，因此形参的操作，不影响原始内容。如果是对引用类型的数据进行操作，分两种情况，一种是形参和实参保持指向同一个对象地址，则形参的操作，会影响实参指向的对象的内容。一种是形参被改动指向新的对象地址（如重新赋值引用），则形参的操作，不会影响实参指向的对象的内容。
#####4. java中==和equals和hashCode的区别
#####5. int、char、long各占多少字节数
#####6. int与integer的区别
#####7. 探探对java多态的理解
#####8. 面对接口  DIP
#####9. String、StringBuffer、StringBuilder区别
#####10. 什么是内部类？内部类的作用
#####11. 抽象类和接口区别
#####12. 抽象类的意义
#####13. 抽象类与接口的应用场景
#####14. 抽象类是否可以没有方法和属性？
#####15. 接口的意义
#####16. 泛型中extends和super的区别
#####17. 父类的静态方法能否被子类重写
#####18. 进程和线程的区别
#####19. final，finally，finalize的区别
#####20. 序列化的方式
#####21. Serializable 和Parcelable 的区别
#####22. 静态属性和静态方法是否可以被继承？是否可以被重写？以及原因？
#####23. 静态内部类的设计意图
#####24. 成员内部类、静态内部类、局部内部类和匿名内部类的理解，以及项目中的应用
#####25. 谈谈对kotlin的理解
#####26. 闭包和局部内部类的区别
#####27. string 转换成 integer的方式及原理
####2、 java深入源码级的面试题（有难度）
#####1. 哪些情况下的对象会被垃圾回收机制处理掉？
#####2. 讲一下常见编码方式？
#####3. utf-8编码中的中文占几个字节；int型几个字节？
#####4. 静态代理和动态代理的区别，什么场景使用？
#####5. Java的异常体系
#####6. 谈谈你对解析与分派的认识。
#####7. 修改对象A的equals方法的签名，那么使用HashMap存放这个对象实例的时候，会调用哪个equals方法？
#####8. Java中实现多态的机制是什么？
#####9. 如何将一个Java对象序列化到文件里？
#####10. 说说你对Java反射的理解
#####11. 说说你对Java注解的理解
#####12. 说说你对依赖注入的理解
#####13. 说一下泛型原理，并举例说明
#####14. Java中String的了解
#####15. String为什么要设计成不可变的？
#####16. Object类的equal和hashCode方法重写，为什么？
#####17 常用数据结构简介
#####18. 并发集合了解哪些？
#####19. 列举java的集合以及集合之间的继承关系
#####20. 集合类以及集合框架
#####21. 容器类介绍以及之间的区别（容器类估计很多人没听这个词，Java容器主要可以划分为4个部分：List列表、Set集合、Map映射、工具类（Iterator迭代器、Enumeration枚举类、Arrays和Collections），具体的可以看看这篇博文 Java容器类）
#####22. List,Set,Map的区别
#####23. List和Map的实现方式以及存储方式
#####24. HashMap的实现原理
#####25. HashMap数据结构？
#####26. HashMap源码理解
#####27. HashMap如何put数据（从HashMap源码角度讲解）？
#####28. HashMap怎么手写实现？
#####29. ConcurrentHashMap的实现原理
#####30. ArrayMap和HashMap的对比
#####31. HashTable实现原理
#####32. TreeMap具体实现
#####33. HashMap和HashTable的区别
#####34. HashMap与HashSet的区别
#####35. HashSet与HashMap怎么判断集合元素重复？
#####36. 集合Set实现Hash怎么防止碰撞
#####37. ArrayList和LinkedList的区别，以及应用场景
#####38. 数组和链表的区别
#####39. 二叉树的深度优先遍历和广度优先遍历的具体实现
#####40. 堆的结构
#####41. 堆和树的区别
#####42. 堆和栈在内存中的区别是什么(解答提示：可以从数据结构方面以及实际实现方面两个方面去回答)？
#####43. 什么是深拷贝和浅拷贝
#####44. 手写链表逆序代码
#####45. 讲一下对树，B+树的理解
#####46. 讲一下对图的理解
#####47. 判断单链表成环与否？
#####48. 链表翻转（即：翻转一个单项链表）
#####49. 合并多个单有序链表（假设都是递增的）


###九、架构
####1.DDD
	DDD实践
	界限上下文
	聚合
	聚合根对象的创建不应该被Spring容器管理，也不应该被注入其它对象
	领域实体
	https://www.jianshu.com/p/Tozpp3

	领域服务
	不是属于单个聚合根的业务或者需要多个聚合根配合的业务，放在领域服务中，注意是业务，如果没有业务，协调工作应该放到应用服务中，静态方法放在领域服务中需要通过rpc等其它外部服务处理业务的，放在领域服务中
	领域事件
	防腐
	SIDE-EFFECT-FREE模式和CQRS
	Martin在blog中指出：CQRS适用于极少数复杂的业务领域，如果不是很适合反而会增加复杂度；另一个适用场景是为了获取高性能的查询服务
##### DDD 微服务
	微服务架构是一种架构风格，它将应用程序构建为以业务域为模型的小型自治服务集合。
	整洁架构最主要原则是依赖原则，它定义了各层的依赖关系，越往里，依赖越低，代码级别越高。外圆代码依赖只能指向内圆，内圆不知道外圆的任何事情。一般来说，外圆的声明（包括方法、类、变量）不能被内圆引用。同样的，外圆使用的数据格式也不能被内圆使用。
      整洁架构各层主要职能如下：
      Entities：实现领域内核心业务逻辑，它封装了企业级的业务规则。一个Entity可以是一个带方法的对象，也可以是一个数据结构和方法集合。
      Use Cases：实现与用户操作相关的服务组合与编排，它包含了应用特有的业务规则，封装和实现了系统的所有用例。
      Interface Adapters：它把适用于Use Cases和entities的数据转换为适用于外部服务的格式，或把外部的数据格式转换为适用于Use Casess和entities的格式。
      Frameworks and Drivers：这是实现所有前端业务细节的地方：UI，Tools，Frameworks等。
      六边形 https://www.jianshu.com/p/5732b69bd1a1
      在六边形架构、DDD分层架构的白框部分以及整洁架构Use Cases和Entities区域实现了核心业务逻辑。但是核心业务逻辑又由两部分来完成：应用层和领域层逻辑。领域层实现了最核心的业务领域部分的逻辑，对外提供领域模型内细粒度的领域服务，应用层依赖领域层业务逻辑，通过服务组合和编排通过API网关向前台应用提供粗粒度的服务
	中台和微服务设计的关键在于合理的分层和领域模型的设计！
      1.聚焦领域模型
      中台属于后端业务领域逻辑范畴，重点关注领域内业务逻辑的实现，通过实现公共需求为前台应用提供共享服务能力。按DDD的方法，在领域模型建立的过程中会对业务和应用进行清晰的逻辑和物理边界划分。领域模型的设计结果会影响到后续的系统模型、架构模型和领域层代码模型的设计，最终影响到微服务的拆分和项目落地实施。

      2.合理的架构分层

      不要把与领域无关的业务逻辑放在领域层，避免领域业务逻辑被污染，保证领域层的纯洁，只有这样才能降低领域逻辑受外部变化的影响。在领域和架构模型建立后，代码模型的逻辑分层和微服务拆分要具体情况具体分析，根据自身研发和运维能力综合考虑。

    （1） 项目级单应用

      对于单应用系统的分层，遵循上述分层架构模型即可，核心领域逻辑在领域层实现，服务的组合和编排在应用层实现，两者组合形成中台，通过API对前台应用提供服务。

      从部署和微服务拆分来讲，领域层代码部署时可能是一个微服务，也可能会根据限界上下文被拆分为多个微服务部署。应用层代码如果逻辑复杂，含较多个性业务逻辑，可以根据需要独立为微服务部署。如果逻辑简单，且领域层是一个微服务，在划分好应用层和领域层代码逻辑边界的情况下，如果符合微服务拆分原则，也可以考虑将应用层与领域层代码合并为一个微服务部署。

    （2）企业级多中台应用

      对于企业级多中台应用，多个中台应用通过API网关对外发布API服务。核心域业务中台在调用支撑域和通用域中台服务时通过核心域应用层完成多中台服务的组合和编排，为前台应用提供API服务。核心域中台的应用层是否独立成微服务部署，需考虑的情况与单应用系统相似。

      3.服务的管理

      应用层、领域层和基础设施层都有对应的服务，各司其职提供服务，其中基础设施层的服务通过依赖反转模式为领域层和应用层提供基础设施资源服务。应用层和领域层服务发布在API网关，通过API网关适配，为前台提供用户无差异化（应用app、批处理或自动化测试）的服务。

      4.资源的适配与解耦
      由于上述架构模型中定义的外层只能依赖内层的架构原则，对于像数据库、缓存、文件系统等的外部基础设施资源，往往采用依赖反转的模式对外提供资源服务，实现应用层、领域层与基础设施层资源的解耦。在设计中应考虑资源层的代码适配逻辑，一旦基础设施资源出现变更（如换数据库），可以屏蔽资源变更对业务代码带来的影响，切断业务逻辑对基础资源的依赖，降低由于资源变更对业务逻辑的影响。
      5. 前台应用
      从核心业务逻辑来看，中台实现了主要的业务逻辑，属于标准化的重量级应用。前台应用聚焦于界面交互以及业务流程等，属于轻量级应用，前台应用可以有个性的业务逻辑、流程和配置数据，甚至数据库，通过调用中台API服务完成交互界面和业务全流程
	领域驱动设计中领域的定义：一个领域本质上可以理解为就是一个问题域，只要是同一个领域，那问题域就相同。所以只要我们确定了系统所属的领域，那这个系统的核心业务，即要解决的关键问题、问题的范围边界就基本确定了。领域的本质是问题域，问题域可能根据需要逐层细分，因此领域可分解为子域，子域或可继续分为子子域。。。

#####如何搭建一个高可用系统
	系统设计：关于高可用系统的一些技术方案
	可靠的系统是业务稳定、快速发展的基石。那么，如何做到系统高可靠、高可用呢？下面从技术方面介绍几种提高系统可靠性、可用性的方法。
	扩展
	扩展是最常见的提升系统可靠性的方法，系统的扩展可以避免单点故障，即一个节点出现了问题造成整个系统无法正常工作。换一个角度讲，一个容易扩展的系统，能够通过扩展来成倍的提升系统能力，轻松应对系统访问量的提升。
	一般地，扩展可以分为垂直扩展和水平扩展：
	垂直扩展：是在同一逻辑单元里添加资源从而满足系统处理能力上升的需求。比如，当机器内存不够时，我们可以帮机器增加内存，或者数据存不下时，我们为机器挂载新的磁盘。
	垂直扩展能够提升系统处理能力，但不能解决单点故障问题。
	优点：扩展简单。
	缺点：扩展能力有限。
	水平扩展：通过增加一个或多个逻辑单元，并使得它们像整体一样的工作。
	水平扩展，通过冗余部署解决了单点故障，同时又提升了系统处理能力。
	优点：扩展能力强。
	缺点：增加系统复杂度，维护成本高，系统需要是无状态的、可分布式的。

	隔离
	隔离，是对什么进行隔离呢？是对系统、业务所占有的资源进行隔离，限制某个业务对资源的占用数量，避免一个业务占用整个系统资源，对其他业务造成影响。
	隔离级别按粒度从小到大，可以分为线程池隔离、进程隔离、模块隔离、应用隔离、机房隔离。在数据库的使用中，还经常用到读写分离。
	线程池隔离：不同的业务使用不同的线程池，避免低优先级的任务阻塞高优先级的任务。或者高优先级的任务过多，导致低优先级任务永远不会执行。
	进程隔离：Linux 中有用于进程资源隔离的 Linux CGroup，通过物理限制的方式为进程间资源控制提供了简单的实现方式，为 Linux Container 技术、虚拟化技术的发展奠定了技术基础。在工作中的实际应用，可以看看这篇文章：日志压缩资源消耗优化: Linux CGroup 的使用。
	模块隔离、应用隔离：很多线上故障的发生源于代码修改后，测试不到位导致。按照代码或业务的易变程度来划分模块或应用，把变化较少的划分到一个模块或应用中，变化较多的划分到另一个模块或应用中。减少代码修改影响的范围，也就减少了测试的工作量，减少了故障出现的概率。
	机房隔离：主要是为了避免单个机房网络问题或断电吧。
	读写分离：一方面，将对实时性要求不高的读操作，放到 DB 从库上执行，有利于减轻 DB 主库的压力。另一方面，将一些耗时离线业务 sql 放到 DB 从库上执行，能够减少慢 sql 对 DB 主库的影响，保证线上业务的稳定可靠。
	解耦
	在软件工程中，对象之间的耦合度就是对象之间的依赖性。对象之间的耦合越高，维护成本越高，因此对象的设计应使模块之间的耦合度尽量小。在软件架构设计中，模块之间的解耦或者说松耦合有两种，假设有两个模块A、B，A依赖B：
	第一种是，模块A和模块B只通过接口交互，只要接口设计不变，那么模块B内部细节的变化不影响模块A对模块B服务能力的消费。
	面向接口设计下真正实现了将接口契约的定义和接口的实现彻底分离，实现变化不影响到接口契约，自然不影响到基于接口的交互。
	模块A和B之间的松耦合，主要通过合理的模块划分、接口设计来完成。如果出现循环依赖，可以将模块A、B共同依赖的部分移除到另一个模块C中，将A、B之间的相互依赖，转换为A、B同时对C的依赖。
	第二种是，将同步调用转换成异步消息交互。
	比如在买机票系统中，机票支付完成后需要通知出票系统出票、代金券系统发券。如果使用同步调用，那么出票系统、代金券系统宕机是会影响到机票支付系统，如果另一个系统比如专车系统也想要在机票支付完成后向用户推荐专车服务，那么同步调用模式下机票支付系统就需要为此而改动，容易影响核心支付业务的可靠性。
	如果我们将同步调用替换成异步消息，机票支付系统发送机票支付成功的消息到消息中间件，出票系统、代金券系统从消息中间件订阅消息。这样一来，出票系统、代金券系统的宕机也就不会对机票支付系统造成任何影响了。专车系统想要知道机票支付完成这一事件，也只需要从消息中间件订阅消息即可，机票支付系统完全不需要做任何改动。
	异步消息解耦，适合那些信息流单向流动（类似发布-订阅这样的），实时性要求不高的系统。常见的开源消息队列框架有：Kafka、RabbitMQ、RocketMQ。

	限流
	为什么要做限流呢？举一个生活中的例子，大家早上上班都要挤地铁吧，地铁站在早高峰的时候经常要限制客流，为什么呢？有人会觉得这是人为添堵。真是这样吗？如果不执行客流控制，大家想想会是什么场景呢？站台到处都挤满了乘客，就算你使出洪荒之力也不一定能顺利上车，且非常容易引发肢体碰撞，造成冲突。有了客流控制之后，地铁站才能变得秩序井然，大家才能安全上地铁。
	一个系统的处理能力是有上限的，当服务请求量超过处理能力，通常会引起排队，造成响应时间迅速提升。如果对服务占用的资源量没有约束，还可能因为系统资源占用过多而宕机。因此，为了保证系统在遭遇突发流量时，能够正常运行，需要为你的服务加上限流。
	常见的限流算法有：漏桶、令牌桶、滑动窗口计数。
	按照计数范围，可以分为：单机限流、全局限流。单机限流，一般是为了应对突发流量，而全局限流，通常是为了给有限资源进行流量配额。
	按照计数周期，可以分为：QPS、并发（连接数）。
	按照阈值设定方式的不同，可以分为：固定阈值、动态阈值。

	降级
	业务降级，是指牺牲非核心的业务功能，保证核心功能的稳定运行。简单来说，要实现优雅的业务降级，需要将功能实现拆分到相对独立的不同代码单元，分优先级进行隔离。在后台通过开关控制，降级部分非主流程的业务功能，减轻系统依赖和性能损耗，从而提升集群的整体吞吐率。
	降级的重点是：业务之间有优先级之分。降级的典型应用是：电商活动期间关闭非核心服务，保证核心买买买业务的正常运行。
	业务降级通常需要通过开关工作，开关一般做成配置放在专门的配置系统，配置的修改最好能够实时生效，毕竟要是还得修改代码发布那就太 low 了。开源的配置系统有阿里的diamond、携程的Apollo、百度的disconf。
	降级往往需要兜底方案的配合，比如系统不可用的时候，对用户进行提示，安抚用户。提示虽然不起眼，但是能够有效的提升用户体验。

	熔断
	谈到熔断，不得不提经典的电力系统中的保险丝，当负载过大，或者电路发生故障时，电流会不断升高，为防止升高的电流有可能损坏电路中的某些重要器件或贵重器件，烧毁电路甚至造成火灾。保险丝会在电流异常升高到一定的高度和热度的时候，自身熔断切断电流，从而起到保护电路安全运行的作用。
	同样，在分布式系统中，如果调用的远程服务或者资源由于某种原因无法使用时，没有这种过载保护，就会导致请求阻塞在服务器上等待从而耗尽服务器资源。很多时候刚开始可能只是系统出现了局部的、小规模的故障，然而由于种种原因，故障影响的范围越来越大，最终导致了全局性的后果。而这种过载保护就是大家俗称的熔断器(Circuit Breaker)。
	服务正常运行时的 Closed 状态，当服务调用失败量或失败率达到阈值时，熔断器进入 Open 状态
	在 Open 状态，服务调用不会真正去请求外部资源，会快速失败。
	当进入 Open 状态一段时间后，进入 Half-Open状态，需要去尝试调用几次服务，检查故障的服务是否恢复。如果成功则熔断器关闭，如果失败，则再次进入 Open 状态。
	熔断器基本原理
	目前比较流行的降级熔断框架，是由 Netflix 开源的 Hystrix 框架。
	发布相关
	模块级自动化测试
	众所周知，一个项目上线前需要经历严格的测试过程，但是随着业务不断迭代、系统日益复杂，研发工程师、产品经理、测试工程师等都在测试过程中投入了大量精力，而一个个线上故障却表明测试效果并不是那么完美。究其原因，目前的测试工作主要存在两方面问题：
	测试范围难以界定：随着业务逻辑的不断迭代、系统的不断拆分与细化，精确评估项目改动的影响范围变得越来越困难，从而很难梳理出覆盖全面的测试点。
	case验证成本过高：验证一个case需要构造测试场景，包括数据的准备和运行环境的准备，当case量较大或者存在一些涉及多个系统模块且触发条件复杂的case时，这一过程也将花费大量的时间。
	解决上述问题可以使用模块级自动化测试。具体方案是：针对某一模块，收集模块线上的输入、输出、运行时环境等信息，在离线测试环境通过数据mock模块线上场景，回放收集的线上输入，相同的输入比较测试场景与线上收集的输出作为测试结果。
	模块级自动化测试通过简化复杂系统中的不变因素（mock），将系统的测试边界收拢到改动模块，将复杂系统的整体测试转化为改动模块的单元测试。主要适用于系统业务回归，对系统内部重构场景尤其适用。
	具体如何收集线上数据呢？有两种方法：
	AOP：面向切面编程，动态地织入代码，对原有代码的侵入性较小。
	埋点：很多公司都开发了一下基础组件，可以在这些基础组件中嵌入数据收集的代码。
	更多细节，可以查看下面参考文献中的文章：Qunar 自动化测试框架 ARES。
	灰度发布 & 回滚
	单点和发布是系统高可用最大的敌人。一般在线上出现故障后，第一个要考虑的就是刚刚有没有代码发布、配置发布，如果有的话就先回滚。线上故障最重要的是快速恢复，如果等你细细看代码找到问题，没准儿半天就过去了。
	为了减少发布引起问题的严重程度，通常会使用灰度发布策略。灰度发布是速度与安全性作为妥协。他是发布众多保险的最后一道，而不是唯一的一道。在这篇文章来自 Google 的高可用架构理念与实践里提到：
	做灰度发布，如果是匀速的，说明没有理解灰度发布的意义。一般来说阶段选择上从 1% -> 10% -> 100% 的指数型增长。这个阶段，是根据具体业务不同按维度去细分的。
	这里面的重点在于 1% 并不全是随机选择的，而是根据业务特点、数据特点选择的一批有极强的代表性的实例，去做灰度发布的小白鼠。甚至于每次发布的 第一阶段用户(我们叫 Canary/金丝雀)，根据每次发布的特点不同，是人为挑选的。
	发布之前必须制定详细的回滚步骤，回滚是解决发布引起的故障的最快的方法。

	其他
	设置超时：请求对外接口的时候，需要设置合理的超时时间，避免外部接口挂掉时，阻塞整个系统。
	失败重试：失败重试能够提高成功率，但是也会造成响应时间变慢，服务提供方压力倍增。具体要不要重试要根据具体情况决定：对响应时间有要求吗？接口失败率如何？重试会不会造成雪崩？

	总结
	技术	解决什么问题
	扩展	通过冗余部署，避免单点故障
	隔离	1. 避免业务之间的相互影响 2. 机房隔离避免单点故障
	解耦	减少依赖，减少相互间的影响
	限流	遇到突发流量时，保证系统稳定
	降级	牺牲非核心业务，保证核心业务的高可用
	熔断	减少不稳定的外部依赖对核心服务的影响
	自动化测试	通过完善的测试，减少发布引起的故障
	灰度发布	灰度发布是速度与安全性作为妥协，能够有效减少发布故障

#####哪些设计模式可以增加系统的可扩展性
	架构真经
	SOLID
	可扩展性：
	工厂模式
	抽象工厂模式
	观察者模式：很方便增加观察者，方便系统扩展
	模板方法模式：很方便的实现不稳定的扩展点，完成功能的重用
	适配器模式：可以很方便地对适配其他接口
	代理模式：可以很方便在原来功能的基础上增加功能或者逻辑
	责任链模式：可以很方便得增加拦截器/过滤器实现对数据的处理，比如struts2的责任链
	策略模式：通过新增策略从而改变原来的执行策略
#####介绍设计模式，如模板模式，命令模式，策略模式，适配器模式、桥接模式、装饰模式，观察者模式，状态模式，访问者模式。

#####什么是高内聚低耦合，请举例子如何实现
	依赖倒置，开闭、接口替换、
#####什么情况用接口，什么情况用消息
	延迟  返回
	接口的特点是同步调用，接口实时响应，阻塞等待
	消息的特点是异步处理，非实时响应，消息发送后则返回，消息队列可以削峰
	一般对实时性要求比较高的功能采用接口
	对实时性要求不高的功能可以采用消息，削峰时可以采用消息
#####如果AB两个系统互相依赖，如何解除依赖
	DI API  异步消息
#####什么场景应该拆分系统，什么场景应该合并系统
	拆分系统：
	当系统通过集群的方式已经无法解决性能问题的时候，或者业务扩展到很大的时候，需要把拆分系统
	按照业务的方式垂直拆分：将业务功能结合比较紧密的部分拆分成独立的系统，独立维护
	按照性能瓶颈点拆分：将系统性能瓶颈点拆分出一个独立的系统，可以针对这个独立的系统集群部署，增加可伸缩性，提高系统整体的性能
	合并系统：
	或者系统间通过跨进程访问的性能损耗过高，可以将系统合并成一个系统，减少跨进程访问的消耗
####编程原则：
	SOLID 单一职责、开闭原则、里是替换、接口隔离、依赖倒置
	接口隔离原则：https://www.jianshu.com/p/4ce9db323348
#####责任链模式
	https://www.bbsmax.com/A/D854XAx35E/
	在Netty里，pipeline中维护了一个handler的链表。每当事件触发时，就会从双向链表的头部(对于downstream事件则是尾部)开始遍历，这样每个handler都会对事件进行处理。在handler里，可以根据事件类型做相应的处理后传至下一个handler继续处理(甚至可以截断处理链)。
	需要注意的是，单次流程是在一个线程中实现的，是串行的。因此如果其中一个handler是阻塞的，就会影响整体的效果。
	当然netty也已经提供了解决方案，可以通过继承ExecutionHandler的handler来处理这类耗时的操作
	关于责任链模式
	优点降低耦合度。它将请求的发送者和接收者解耦简化了对象，使得对象不需要知道链的结构增强给对象指派职责的灵活性，允许动态地新增或者删除责任链增加新的请求处理类方便
	缺点不能保证请求一定被接收；系统性能将受到一定影响，调试时不方便，可能会造成循环调用，上下文模糊，Handler一定要串行，并行滥用，可读性差。及时调整。
####2. 可用性
	容错机制：
	1.failover：失效转移
	Fail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用
	2.failfast：快速失败
	从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。
	具体分析 https://blog.csdn.net/fan2012huan/article/details/51076970
	ArrayList 使用自身的remove ：会修改modCount（修改记录数）导致expertModCount和	modCount不等
	使用Iterator 的remove 会修改modCount 并将expertModCount置为modCount，所以单线程下不会导致ConcurrentModificationException，但是多线程下，仍然会有可能导致ConcurrentModificationException。  
	Fastfail 提供的是一种快速检测失败机制
	3.failback：失效自动恢复
	Fail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复
	4.failsafe：失效安全
	Fail-Safe的含义为“失效安全”，即使在故障的情况下也不会造成伤害或者尽量减少伤害。维基百科上一个形象的例子是红绿灯的“冲突监测模块”当监测到错误或者冲突的信号时会将十字路口的红绿灯变为闪烁错误模式，而不是全部显示为绿灯。 
####Java SPI
	https://www.cnblogs.com/yaowen/p/10839507.html
	利用了线程上下文ClassLoader
	2.线程上下文类加载器的重要性：
	SPI（Service Provider Interface，服务提供者接口，指的是JDK提供标准接口，具体实现由厂商决定。例如sql）
	父ClassLoader可以使用当前线程Thread.current.currentThread().getContextClassLoader()所指定的classLoader加载的类。这就改变了父ClassLoader不能使用子ClassLoader加载的类的情况，即改变了双亲委托模型。
	线程上下文类加载器就是当前线程的CurrentClassloader
####ClassLoader 
	NoClassDefFoundError vs ClassNotFoundException 
	nice slide of all differences between java.lang.NoClassDefFoundError and java.lang.ClassNotFoundException in Java
	ClassLoader 核心的loadClass与findClass 
	loadClass里面调用findClass，如果自定义的方法不想违背双亲委派模型，则只需要重写findclass方法即可，如果想违背双亲委派模型，则还需要重写loadclass方法。

####限流
	一是 QPS    二是并发线程数	
	降级预案  灰度  流量
	Sentinel使用的是滑动窗口算法
####缓存
#####缓存一致性问题：
	先删除缓存，更新数据库，然后监听数据库binlog，再次删除缓存（双删）
	https://blog.csdn.net/koli6678/article/details/88202245
	缓存击穿、雪崩问题：
	1、缓存穿透
	访问一个不存在的key，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉。
	解决方案
	（1）采用布隆过滤器，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤；
	（2）拦截器，id<=0的直接拦截。
	（3）从cache和db都取不到，可以将key-value写为key-null，设置较短过期时间，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。
#####缓存击穿
	一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。
	解决方案
	（1）设置热点数据永远不过期。
	（2）加互斥锁。
#####缓存雪崩
      大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。
	解决方案
	（1）缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
	（2）如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
	（3）设置热点数据永远不过期。
	多级缓存：主要是解决热点数据问题，  没使用到，可以提。 多级缓存的一致性，多核CPU的MESI  https://www.cnblogs.com/z00377750/p/9180644.html
	多级缓存，本地缓存的更新   强制接口SDK更新
	缓存预热     热点缓存数据比较多，可以提前预热.  
	场景：缓存验证码次数，超时时间; 配置数据
####消息队列
####分布式调度
####流程引擎
JBPM  Activiti  Spring stateMachine 

###十、基本编程练习
####1.IO 
#####字符流和字节流有什么区别？
	要把一片二进制数据数据逐一输出到某个设备中，或者从某个设备中逐一读取一片二进制数据，不管输入输出设备是什么，我们要用统一的方式来完成这些操作，用一种抽象的方式进行描述，这个抽象描述方式起名为IO流，对应的抽象类为OutputStream和InputStream ，不同的实现类就代表不同的输入和输出设备，它们都是针对字节进行操作的。
	字符流处理的单元为2个字节的Unicode字符，分别操作字符、字符数组或字符串；而字节流处理单元为1个字节，操作字节和字节数组。所以字符流是由Java虚拟机将字节转化为2个字节的Unicode字符为单位的字符而成的，如果是音频文件、图片、歌曲，就用字节流好点（避免数据丢失），如果是关系到中文（文本）的，用字符流好点在应用中，经常要完全是字符的一段文本输出去或读进来，用字节流可以吗？计算机中的一切最终都是二进制的字节形式存在。对于“中国”这些字符，首先要得到其对应的字节，然后将字节写入到输出流。读取时，首先读到的是字节，可是我们要把它显示为字符，我们需要将字节转换成字符。由于这样的需求很广泛，人家专门提供了字符流的包装类。底层设备永远只接受字节数据，有时候要写字符串到底层设备，需要将字符串转成字节再进行写入。字符流是字节流的包装，字符流则是直接接受字符串，它内部将串转成字节，再写入底层设备，这为我们向IO设别写入或读取字符串提供了一点点方便。
	 要么使用字节流向buffer里面读byte然后转string。要么直接使用bufferedReader直接读字符流inputStreamReader的内容

####NIO
	Java 中的 BIO、NIO和 AIO 理解为是 Java 语言对操作系统的各种 IO 模型的封装。程序员在使用这些 API 的时候，不需要关心操作系统层面的知识，也不需要根据不同操作系统编写不同的代码。只需要使用Java的API就可以了。
	在讲 BIO,NIO,AIO 之前先来回顾一下这样几个概念：同步与异步，阻塞与非阻塞。
	同步与异步
	同步：同步就是发起调用之后，被调用这未处理完请求之前，调用不返回
	异步：异步就是发起调用后，立即得到被调用方的回应，但被调用者并没有返回结果，调用方还可以处理其他请求，被调用方依靠事件回调机制通知调用者返回结果
	同步和异步的区别最大在于异步的话调用者不需要等待处理结果，被调用者会通过回调等机制来通知调用者其返回结果。
	阻塞和非阻塞
	阻塞就是发起一个请求，调用者一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续
	非阻塞就是发起一个请求，调用者不用一直等着结果返回，可以先去干其他事情
	BIO同步阻塞I/O模式，数据的读取写入必须阻塞在一个线程内等待其完成。
	采用 BIO 通信模型 的服务端，通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在 while(true) 循环中服务端会调用 accept() 方法等待接收客户端的连接的方式监听请求，请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。
	如果要让 BIO 通信模型 能够同时处理多个客户端请求，就必须使用多线程（主要原因是 socket.accept()、 socket.read()、 socket.write() 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 一请求一应答通信模型 。我们可以设想一下如果这个连接不做任何事情的话就会造成不必要的线程开销，不过可以通过 线程池机制 改善，线程池还可以让线程的创建和回收成本相对较低。使用FixedThreadPool 可以有效的控制了线程的最大数量，保证了系统有限的资源的控制，实现了N(客户端请求数量):M(处理客户端请求的线程数量)的伪异步I/O模型（N 可以远远大于 M），下面一节"伪异步 BIO"中会详细介绍到。
	我们再设想一下当客户端并发访问量增加后这种模型会出现什么问题？
	在 Java 虚拟机中，线程是宝贵的资源，线程的创建和销毁成本很高，除此之外，线程的切换成本也是很高的。尤其在 Linux 这样的操作系统中，线程本质上就是一个进程，创建和销毁线程都是重量级的系统函数。如果并发访问量增加会导致线程数急剧膨胀可能会导致线程堆栈溢出、创建新线程失败等问题，最终导致进程宕机或者僵死，不能对外提供服务。
	伪异步 IO
	为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题，后来有人对它的线程模型进行了优化一一一后端通过一个线程池来处理多个客户端的请求接入，形成客户端个数M：线程池最大线程数N的比例关系，其中M可以远远大于N.通过线程池可以灵活地调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。
	采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，它的模型图如上图所示。当有新的客户端接入时，将客户端的 Socket 封装成一个Task（该任务实现java.lang.Runnable接口）投递到后端的线程池中进行处理，JDK 的线程池维护一个消息队列和 N 个活跃线程，对消息队列中的任务进行处理。由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。
	伪异步I/O通信框架采用了线程池实现，因此避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。不过因为它的底层任然是同步阻塞的BIO模型，因此无法从根本上解决问题。
	 总结
	在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的 I/O 并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。因此，我们需要一种更高效的 I/O 处理模型来应对更高的并发量。
	NIO是一种同步非阻塞的I/O模型，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。
	NIO中的N可以理解为Non-blocking，不单纯是New。它支持面向缓冲的，基于通道的I/O操作方法。 NIO提供了与传统BIO模型中的 Socket 和 ServerSocket 相对应的 SocketChannel 和 ServerSocketChannel 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。
	NIO的特性/NIO与IO区别
	如果是在面试中回答这个问题，我觉得首先肯定要从 NIO 流是非阻塞 IO 而 IO 流是阻塞 IO 说起。然后，可以从 NIO 的3个核心组件/特性为 NIO 带来的一些改进来分析。如果，你把这些都回答上了我觉得你对于 NIO 就有了更为深入一点的认识，面试官问到你这个问题，你也能很轻松的回答上来了。
	1)Non-blocking IO（非阻塞IO）
	IO流是阻塞的，NIO流是不阻塞的。
	Java NIO使我们可以进行非阻塞IO操作。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到buffer中后，线程再继续处理数据。写数据也是一样的。另外，非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。
	Java IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了
	2)Buffer(缓冲区)
	IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。
	Buffer是一个对象，它包含一些要写入或者要读出的数据。在NIO类库中加入Buffer对象，体现了新库与原I/O的一个重要区别。在面向流的I/O中·可以将数据直接写入或者将数据直接读到 Stream 对象中。虽然 Stream 中也有 Buffer 开头的扩展类，但只是流的包装类，还是从流读到缓冲区，而 NIO 却是直接读到 Buffer 中进行操作。
	在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。
	最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。
	3)Channel (通道)
	NIO 通过Channel（通道） 进行读写。
	通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。
	4)Selectors(选择器)
	NIO有选择器，而IO没有。
	选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。
	NIO 读数据和写数据方式
	通常来说NIO中的所有IO都是从 Channel（通道） 开始的。
	从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据
	从通道进行数据写入：创建一个缓冲区，填充数据，并要求写入通道数据
#####NIO核心组件简单介绍
	NIO 包含下面几个核心的组件：
	Channel（通道）
	Buffer（缓冲区）
	Selector（选择器）
	整个NIO体系包含的类远远不止这三个，只能说这三个是NIO体系的“核心API”。我们上面已经对这三个概念进行了基本的阐述，这里就不多做解释了。
	为什么大家都不愿意用 JDK 原生 NIO 进行开发呢？从上面的代码中大家都可以看出来，是真的难用！除了编程复杂、编程模型难之外，它还有以下让人诟病的问题：
	JDK的NIO底层由epoll实现，该实现饱受诟病的空轮询bug会导致cpu飙升100%。
#####AIO (Asynchronous I/O)
	AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。
	AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的，这一点可以从底层IO线程模型解释，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。
#####netty事件驱动机制
#####Netty是如何使用线程池的，为什么这么使用
#####NIO的好处,Netty线程模型,什么是零拷贝
	Netty通过Reactor模型基于多路复用器接收并处理用户请求，内部实现了两个线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件，由对应的Handler处理。
	netty 优化粘包问题   https://www.jianshu.com/p/5857d80d9dec
	TCP是以流的方式来处理数据，一个完整的包可能会被TCP拆分成多个包进行发送，也可能把小的封装成一个大的数据包发送。TCP粘包/分包的原因：
	应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生拆包现象，而应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包现象；进行MSS大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包
	以太网帧的payload（净荷）大于MTU（1500字节）进行ip分片。
	解决方法
	消息定长：FixedLengthFrameDecoder类
		包尾增加特殊字符分割：行分隔符类：LineBasedFrameDecoder或自定义分隔符类 ：DelimiterBasedFrameDecoder
	将消息分为消息头和消息体：LengthFieldBasedFrameDecoder类。分为有头部的拆包与粘包、长度字段在前且有头部的拆包与粘包、多扩展头部的拆包与粘包。
	netty给我提供了各种方式供我们使用。
	1、DelimiterBasedFrameDecoder是基于消息边界方式进行粘包拆包处理的。
	2、FixedLengthFrameDecoder是基于固定长度消息进行粘包拆包处理的。
	3、LengthFieldBasedFrameDecoder是基于消息头指定消息长度进行粘包拆包处理的。
	4、LineBasedFrameDecoder是基于行来进行消息粘包拆包处理的。
	用户可以自行选择规则然后使用Netty提供的对应的Decoder来进行具有粘包、拆包处理功	能的网络应用开发。
	netty 的zero-copy https://www.jianshu.com/p/69fd6d094771
	Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。堆内存多了一次内存拷贝，JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。ByteBuffer由ChannelConfig分配，而ChannelConfig创建ByteBufAllocator默认使用Direct Buffer
	CompositeByteBuf 类可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的Buffer。addComponents方法将 header 与 body 合并为一个逻辑上的 ByteBuf, 这两个 ByteBuf 在CompositeByteBuf 内部都是单独存在的, CompositeByteBuf 只是逻辑上是一个整体
	通过 FileRegion 包装的FileChannel.tranferTo方法 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环write方式导致的内存拷贝问题。
	通过 wrap方法, 我们可以将 byte[] 数组、ByteBuf、ByteBuffer等包装成一个 Netty ByteBuf 对象, 进而避免了拷贝操作。
	Selector BUG：若Selector的轮询结果为空，也没有wakeup或新消息处理，则发生空轮询，CPU使用率100%，
	Netty的解决办法：对Selector的select操作周期进行统计，每完成一次空的select操作进行一次计数，若在某个周期内连续发生N次空轮询，则触发了epoll死循环bug。重建Selector，判断是否是其他线程发起的重建请求，若不是则将原SocketChannel从旧的Selector上去除注册，重新注册到新的Selector上，并将原来的Selector关闭

###十二、开发性
#####介绍你做过的哪些项目
#####都使用过哪些框架、平台？
#####都使用过哪些自定义控件？
#####研究比较深入的领域有哪些？
#####对业内信息的关注渠道有哪些？
#####最近都读哪些书？
#####有没有什么开源项目？
#####自己最擅长的技术点，最感兴趣的技术领域和技术点
#####项目中用了哪些开源库，如何避免因为引入开源库而导致的安全性和稳定性问题
#####实习过程中做了什么，有什么产出？
#####看过哪些开源框架的源码


#####Hbase存储
	首先HBase不同于一般的关系数据库,它是一个适合于非结构化数据存储的数据库.另一个不同的是HBase基于列的而不是基于行的模式.使用的直接就是HDFS文件系统